{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, GlobalAveragePooling2D, Dense, Conv2DTranspose, Flatten, LeakyReLU, Reshape\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from skimage import exposure\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f9e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Linux Paths for CheXpert Dataset\n",
    "\n",
    "train_dir = os.path.abspath(\"/media/nicholasjprimiano/8A5C72285C720F67/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/train.csv\")\n",
    "traindf=pd.read_csv(train_dir, dtype=str)\n",
    "\n",
    "valid_dir = os.path.abspath(\"/media/nicholasjprimiano/8A5C72285C720F67/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/valid.csv\")\n",
    "validdf=pd.read_csv(valid_dir, dtype=str)\n",
    "\n",
    "for i in range(len(traindf)):\n",
    "    traindf.iloc[i,0] = \"/media/nicholasjprimiano/8A5C72285C720F67/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/\" + traindf.iloc[i,0]\"\"\"\n",
    "    \n",
    "#Windows Paths for CheXpert Dataset\n",
    "train_dir = os.path.abspath(r\"C:/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/train.csv\")\n",
    "traindf=pd.read_csv(train_dir, dtype=str)\n",
    "\n",
    "#Modify dataframe path\n",
    "for i in range(len(traindf)):\n",
    "    traindf.iloc[i,0] = r\"C:/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/\" + traindf.iloc[i,0]\n",
    "\n",
    "#valid_dir = os.path.abspath(r\"C:/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/valid.csv\")\n",
    "#validdf=pd.read_csv(valid_dir, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66353564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only looking at AP (anterior-posterior) view xrays\n",
    "aptrainlist = []\n",
    "for i in range(len(traindf)):\n",
    "    if (traindf.iloc[i,4] == \"AP\"):\n",
    "        aptrainlist.append(traindf.iloc[i,:])\n",
    "\n",
    "aptraindf = pd.DataFrame(aptrainlist)\n",
    "\n",
    "#Only looking at xrays labeled Pneumothorax\n",
    "paths = []\n",
    "for i in range(len(aptraindf[aptraindf[\"Pneumothorax\"] == \"1.0\"][\"Path\"])):\n",
    "    paths.append(aptraindf[aptraindf[\"Pneumothorax\"] == \"1.0\"][\"Path\"].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f9f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization called in get_imgs() not used right now\n",
    "def normalize_xray(img):\n",
    "    hist_normal = exposure.equalize_adapthist(img/np.max(img))   \n",
    "    #clache_hist_normal = exposure.equalize_adapthist(hist_normal /np.max(hist_normal))\n",
    "    #return clache_hist_normal\n",
    "    return hist_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 128x128 images\n",
    "\n",
    "IMG_SIZE = 128\n",
    "def get_imgs(paths):\n",
    "    images = []\n",
    "    for i in paths:\n",
    "        #Normalized\n",
    "        images.append(normalize_xray(cv2.cvtColor(cv2.resize(cv2.imread(i),(IMG_SIZE,IMG_SIZE)), cv2.COLOR_BGR2GRAY)))\n",
    "        #Gray Scale \n",
    "        #images.append(cv2.cvtColor(cv2.resize(cv2.imread(i),(IMG_SIZE,IMG_SIZE)), cv2.COLOR_BGR2GRAY))\n",
    "    return images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train array of images with values between 0 and 1\n",
    "X_train = np.array(get_imgs(paths)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaped X train and shifted pixzel values between -1 and 1 for tanh \n",
    "X_train_dcgan = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1) * 2. - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "codings_size = 100\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(8 * 8 * 1024, input_shape=[codings_size], activation=\"relu\"),\n",
    "    keras.layers.Reshape([8, 8, 1024]),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2DTranspose(512, kernel_size=5, strides=2, padding=\"SAME\",activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2DTranspose(256, kernel_size=5, strides=2, padding=\"SAME\",activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2DTranspose(128, kernel_size=5, strides=2, padding=\"SAME\",activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"SAME\",activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(1, kernel_size=5, strides=1, padding=\"SAME\",\n",
    "                                 activation=\"tanh\"),\n",
    "])\n",
    "generator.summary()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "codings_size = 100\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(16 * 16 * 128, input_shape=[codings_size]),\n",
    "    keras.layers.Reshape([16, 16, 128]),\n",
    "\n",
    "    keras.layers.Conv2DTranspose(128, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                                 activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                                 activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "                                 \n",
    "    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                                 activation=\"tanh\"),\n",
    "])\n",
    "generator.summary()\n",
    "\n",
    "\n",
    "discriminator = keras.models.Sequential([\n",
    "\n",
    "    keras.layers.Conv2D(64, kernel_size=5, strides=1, padding=\"SAME\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2),\n",
    "                        input_shape=[128, 128, 1]),\n",
    "    \n",
    "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(256, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(512, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "discriminator.summary()\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2),\n",
    "                        input_shape=[128, 128, 1]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(256, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d902ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "codings_size = 100\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "\n",
    "    keras.layers.Dense(128 * 32* 32, activation=\"relu\", input_shape=[codings_size]),\n",
    "    keras.layers.Reshape((32,32, 128)),\n",
    "    keras.layers.UpSampling2D(),\n",
    "    \n",
    "    #keras.layers.GaussianNoise(stddev=.1),\n",
    "    keras.layers.Conv2D(128, kernel_size=3, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(momentum=0.8),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.UpSampling2D(),\n",
    "    \n",
    "    #keras.layers.GaussianNoise(stddev=.1),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(momentum=0.8),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Conv2D(1, kernel_size=3, padding=\"same\"),\n",
    "    keras.layers.Activation(\"tanh\")\n",
    "\n",
    "])\n",
    "generator.summary()\n",
    "\n",
    "discriminator = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, kernel_size=3, strides=2, input_shape=[128, 128, 1], padding=\"same\"),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\"),\n",
    "    keras.layers.ZeroPadding2D(padding=((0,1),(0,1))),\n",
    "    keras.layers.BatchNormalization(momentum=0.8),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\"),\n",
    "    BatchNormalization(momentum=0.8),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(momentum=0.8),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fc78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_smoothing(y_true,y_pred):\n",
    "     return tf.keras.losses.binary_crossentropy(y_true,y_pred, label_smoothing=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fbb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=label_smoothing, optimizer=tf.keras.optimizers.Adam(lr = 0.0002, beta_1 = 0.7, beta_2 = 0.9))\n",
    "discriminator.trainable = False\n",
    "\n",
    "#Changed from std Adam optimizer\n",
    "\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "\n",
    "#changed from 128 - smaller batches seem to yeild better results\n",
    "batch_size = 8\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train_dcgan)\n",
    "dataset = dataset.shuffle(250)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f83c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=500):\n",
    "    generator, discriminator = gan.layers\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))   \n",
    "           \n",
    "        for X_batch in dataset:\n",
    "            # phase 1 - training the discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_images = generator(noise)\n",
    "\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            d_loss = discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "\n",
    "            # phase 2 - training the generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, y2)\n",
    "            \n",
    "        if epoch % 5 == 0:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        print(\"g_loss\", g_loss)  \n",
    "        print(\"d_loss\", d_loss) \n",
    "        \n",
    "        plt.imshow(generator(noise)[0,:,:,:] + 1, cmap=\"gray\")\n",
    "        #print(str(generator(noise)[0,:,:,:]))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc841fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Bad attempt at splitting up fake and real batchs\n",
    "\n",
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=500):\n",
    "    generator, discriminator = gan.layers\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))   \n",
    "           \n",
    "        for X_batch in dataset:\n",
    "            # phase 1 - training the discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_images = generator(noise)    \n",
    "\n",
    "            # generate 'fake' examples\n",
    "            X_fake = generated_images\n",
    "            y_fake = tf.constant([[0.]] * batch_size)\n",
    "\n",
    "            X_real =  X_batch\n",
    "            y_real = tf.constant([[1.]] * batch_size)\n",
    "\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_real, y_real)\n",
    "            # update discriminator model weights\n",
    "            d_loss = discriminator.train_on_batch(X_fake, y_fake)\n",
    "\n",
    "\n",
    "            # phase 2 - training the generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, y2)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        print(\"g_loss\", g_loss)  \n",
    "        print(\"d_loss\", d_loss) \n",
    "        plt.imshow(generator(noise)[0,:,:,:] + 1, cmap=\"gray\")\n",
    "        #print(str(generator(noise)[0,:,:,:]))\n",
    "        plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e911d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(gan, dataset, batch_size, codings_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab8fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1696fff12340fbeacd8891884860ba5d4999e3a236c837e4d2afed27776e33eb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
