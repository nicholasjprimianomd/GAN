{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvZ0eWCvWEj5"
      },
      "source": [
        "# Wasserstein GAN (W-GAN)\n",
        "\n",
        "Originally proposed by [Arjovsky et al.](https://arxiv.org/pdf/1701.07875.pdf) is their work titled Unsupervised Representation Learning With Deep Convolutions Generative Adversarial Networks. This network uses a basic implementation where generator and discriminator models use convolutional layers, batch normalization and Upsampling.\n",
        "This notebook trains both networks using ADAM optimizer to play the minimax game. We showcase the effectiveness using MNIST digit generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqckn9XdWEj7"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2/blob/master/Chapter_6/wasserstein_gan.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThBnzklKWEj8"
      },
      "source": [
        "## Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERhnWc-JWEj8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "from tensorflow.keras import datasets\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, GlobalAveragePooling2D, Dense, Conv2DTranspose, Flatten, LeakyReLU, Reshape\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "import os\n",
        "import pydicom\n",
        "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
        "from skimage import exposure\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw12Vxx5WEj9"
      },
      "source": [
        "## Load Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKYNqtdIWEj-"
      },
      "outputs": [],
      "source": [
        "from gan_utils import build_critic\n",
        "from gan_utils import build_dc_generator\n",
        "from gan_utils import sample_images\n",
        "from gan_utils import wasserstein_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Linux Paths for CheXpert Dataset\n",
        "\n",
        "train_dir = os.path.abspath(\"/media/nicholasjprimiano/8A5C72285C720F67/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/train.csv\")\n",
        "traindf=pd.read_csv(train_dir, dtype=str)\n",
        "\n",
        "valid_dir = os.path.abspath(\"/media/nicholasjprimiano/8A5C72285C720F67/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/valid.csv\")\n",
        "validdf=pd.read_csv(valid_dir, dtype=str)\n",
        "\n",
        "for i in range(len(traindf)):\n",
        "    traindf.iloc[i,0] = \"/media/nicholasjprimiano/8A5C72285C720F67/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/\" + traindf.iloc[i,0]\"\"\"\n",
        "    \n",
        "#Windows Paths for CheXpert Dataset\n",
        "train_dir = os.path.abspath(r\"C:/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/train.csv\")\n",
        "traindf=pd.read_csv(train_dir, dtype=str)\n",
        "\n",
        "#Modify dataframe path\n",
        "for i in range(len(traindf)):\n",
        "    traindf.iloc[i,0] = r\"C:/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/\" + traindf.iloc[i,0]\n",
        "\n",
        "#valid_dir = os.path.abspath(r\"C:/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/valid.csv\")\n",
        "#validdf=pd.read_csv(valid_dir, dtype=str)\n",
        "\n",
        "#Only looking at AP (anterior-posterior) view xrays\n",
        "aptrainlist = []\n",
        "for i in range(len(traindf)):\n",
        "    if (traindf.iloc[i,4] == \"AP\"):\n",
        "        aptrainlist.append(traindf.iloc[i,:])\n",
        "\n",
        "aptraindf = pd.DataFrame(aptrainlist)\n",
        "\n",
        "#Only looking at xrays labeled Pneumothorax\n",
        "paths = []\n",
        "for i in range(len(aptraindf[aptraindf[\"Pneumothorax\"] == \"1.0\"][\"Path\"])):\n",
        "    paths.append(aptraindf[aptraindf[\"Pneumothorax\"] == \"1.0\"][\"Path\"].iloc[i])\n",
        "\n",
        "    #Normalization called in get_imgs() not used right now\n",
        "def normalize_xray(img):\n",
        "    hist_normal = exposure.equalize_adapthist(img/np.max(img))   \n",
        "    #clache_hist_normal = exposure.equalize_adapthist(hist_normal /np.max(hist_normal))\n",
        "    #return clache_hist_normal\n",
        "    return hist_normal\n",
        "\n",
        "#load 128x128 images\n",
        "\n",
        "IMG_SIZE = 128\n",
        "def get_imgs(paths):\n",
        "    images = []\n",
        "    for i in paths:\n",
        "        #Normalized\n",
        "        images.append(normalize_xray(cv2.cvtColor(cv2.resize(cv2.imread(i),(IMG_SIZE,IMG_SIZE)), cv2.COLOR_BGR2GRAY)))\n",
        "        #Gray Scale \n",
        "        #images.append(cv2.cvtColor(cv2.resize(cv2.imread(i),(IMG_SIZE,IMG_SIZE)), cv2.COLOR_BGR2GRAY))\n",
        "    return images \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbon1hRDWEj-"
      },
      "source": [
        "## W-GAN Training Loop\n",
        "- As proposed in the original paper\n",
        "- Train critic using a mix of fake and real samples\n",
        "- Calculate discriminator loss\n",
        "- Train the critic 5 times per training cycle of the generator\n",
        "- Use Wasserstein_loss for both generator and discriminators\n",
        "- Fix the discriminator and train generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0CjAZYUWEj-"
      },
      "outputs": [],
      "source": [
        "def train(generator=None,discriminator=None,gan_model=None,\n",
        "          epochs=1000, discriminator_cycles=5, batch_size=128, sample_interval=50,\n",
        "          z_dim=100,clip_value = 0.01):\n",
        "    # Load MNIST train samples\n",
        "    #(X_train, _), (_, _) = datasets.mnist.load_data()\n",
        "\n",
        "    # Rescale -1 to 1\n",
        "    #X_train = X_train / 127.5 - 1\n",
        "\n",
        "    #X_train = np.expand_dims(X_train, axis=3)\n",
        "    #X_train array of images with values between 0 and 1\n",
        "    \n",
        "    X_train = np.array(get_imgs(paths)).astype(np.float32)\n",
        "\n",
        "    #reshaped X train and shifted pixzel values between -1 and 1 for tanh \n",
        "    X_train = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1) * 2. - 1.\n",
        "    \n",
        "    # Prepare GAN output labels\n",
        "    real_y = -np.ones((batch_size, 1))\n",
        "    fake_y = np.ones((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # train disriminator\n",
        "        for _ in range(discriminator_cycles):\n",
        "            # pick random real samples from X_train\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            real_imgs = X_train[idx]\n",
        "\n",
        "            # pick random noise samples (z) from a normal distribution\n",
        "            noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "            # use generator model to generate output samples\n",
        "            fake_imgs = generator.predict(noise)\n",
        "\n",
        "            # calculate discriminator loss on real samples\n",
        "            disc_loss_real = discriminator.train_on_batch(real_imgs, real_y)\n",
        "\n",
        "            # calculate discriminator loss on fake samples\n",
        "            disc_loss_fake = discriminator.train_on_batch(fake_imgs, fake_y)\n",
        "\n",
        "            # overall discriminator loss\n",
        "            discriminator_loss = 0.5 * np.add(disc_loss_real, disc_loss_fake)\n",
        "            \n",
        "            # clip weights to ensure adherance to model constraints in EM space\n",
        "            # Clip critic weights\n",
        "            for l in discriminator.layers:\n",
        "                weights = l.get_weights()\n",
        "                weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n",
        "                l.set_weights(weights)\n",
        "        \n",
        "        #train generator\n",
        "        # pick random noise samples (z) from a normal distribution\n",
        "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "\n",
        "        # use trained discriminator to improve generator\n",
        "        gen_loss = gan_model.train_on_batch(noise, real_y)\n",
        "\n",
        "        # training updates\n",
        "        print (\"%d [Discriminator loss: %f] [Generator loss: %f]\" % (epoch,\n",
        "                                                                     1 - discriminator_loss[0], \n",
        "                                                                     1 - gen_loss[0]))\n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if epoch % sample_interval == 0:\n",
        "            sample_images(epoch,generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NGOeu9fWEj_"
      },
      "source": [
        "## Prepare Discriminator Model or Critic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFhA8gdHWEkA",
        "outputId": "a167dead-2690-493a-8c9f-9a42f53395cd"
      },
      "outputs": [],
      "source": [
        "discriminator = build_critic()\n",
        "discriminator.compile(loss=wasserstein_loss,\n",
        "            optimizer=RMSprop(lr=0.00005),\n",
        "            metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x924rksyWEkB"
      },
      "source": [
        "## Prepare Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC0S-D6EWEkB",
        "outputId": "27343f78-415e-433d-8573-bde6dfe86e14"
      },
      "outputs": [],
      "source": [
        "generator = build_dc_generator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVKJCL3zWEkB"
      },
      "source": [
        "## Prepare GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hr3PjnPWEkC",
        "outputId": "7af9b493-051b-45a4-c797-775da1eacb99"
      },
      "outputs": [],
      "source": [
        "# Noise for generator\n",
        "z_dim = 100\n",
        "z = Input(shape=(z_dim,))\n",
        "img = generator(z)\n",
        "\n",
        "# Fix the discriminator\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Get discriminator output\n",
        "valid = discriminator(img)\n",
        "\n",
        "# Stack discriminator on top of generator\n",
        "gan_model = Model(z, valid)\n",
        "gan_model.compile(loss=wasserstein_loss,\n",
        "    optimizer=RMSprop(lr=0.00005),\n",
        "    metrics=['accuracy'])\n",
        "gan_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRrl_XlfWEkC"
      },
      "source": [
        "## Train W-GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM8Mkrt3WEkC"
      },
      "outputs": [],
      "source": [
        "train(generator, discriminator, gan_model, epochs=4000, batch_size=64, sample_interval=100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "wasserstein_gan.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
