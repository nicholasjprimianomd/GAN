{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large amount of credit goes to:\n",
    "# https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py\n",
    "# which I've used as a reference for this implementation\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from functools import partial\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, GlobalAveragePooling2D, Dense, Conv2DTranspose, Flatten, LeakyReLU, Reshape\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from skimage import exposure\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Linux Paths for CheXpert Dataset\n",
    "\n",
    "train_dir = os.path.abspath(\"/media/nicholasjprimiano/8A5C72285C720F67/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/train.csv\")\n",
    "traindf=pd.read_csv(train_dir, dtype=str)\n",
    "\n",
    "valid_dir = os.path.abspath(\"/media/nicholasjprimiano/8A5C72285C720F67/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/valid.csv\")\n",
    "validdf=pd.read_csv(valid_dir, dtype=str)\n",
    "\n",
    "for i in range(len(traindf)):\n",
    "    traindf.iloc[i,0] = \"/media/nicholasjprimiano/8A5C72285C720F67/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/\" + traindf.iloc[i,0]\"\"\"\n",
    "    \n",
    "#Windows Paths for CheXpert Dataset\n",
    "train_dir = os.path.abspath(r\"C:/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/train.csv\")\n",
    "traindf=pd.read_csv(train_dir, dtype=str)\n",
    "\n",
    "#Modify dataframe path\n",
    "for i in range(len(traindf)):\n",
    "    traindf.iloc[i,0] = r\"C:/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/\" + traindf.iloc[i,0]\n",
    "\n",
    "#valid_dir = os.path.abspath(r\"C:/ML_C/CheXpert/CheXpert-Keras-master/data/default_split/CheXpert-v1.0-small/CheXpert-v1.0-small/valid.csv\")\n",
    "#validdf=pd.read_csv(valid_dir, dtype=str)\n",
    "#Only looking at AP (anterior-posterior) view xrays\n",
    "aptrainlist = []\n",
    "for i in range(len(traindf)):\n",
    "    if (traindf.iloc[i,4] == \"AP\"):\n",
    "        aptrainlist.append(traindf.iloc[i,:])\n",
    "\n",
    "aptraindf = pd.DataFrame(aptrainlist)\n",
    "\n",
    "#Only looking at xrays labeled Pneumothorax\n",
    "paths = []\n",
    "for i in range(len(aptraindf[aptraindf[\"Pneumothorax\"] == \"1.0\"][\"Path\"])):\n",
    "    paths.append(aptraindf[aptraindf[\"Pneumothorax\"] == \"1.0\"][\"Path\"].iloc[i])\n",
    "\n",
    "#Normalization called in get_imgs() not used right now\n",
    "def normalize_xray(img):\n",
    "    hist_normal = exposure.equalize_adapthist(img/np.max(img))   \n",
    "    #clache_hist_normal = exposure.equalize_adapthist(hist_normal /np.max(hist_normal))\n",
    "    #return clache_hist_normal\n",
    "    return hist_normal\n",
    "\n",
    "#load 128x128 images\n",
    "IMG_SIZE = 128\n",
    "def get_imgs(paths):\n",
    "    images = []\n",
    "    for i in paths:\n",
    "        #Normalized\n",
    "        #images.append(normalize_xray(cv2.cvtColor(cv2.resize(cv2.imread(i),(IMG_SIZE,IMG_SIZE)), cv2.COLOR_BGR2GRAY)))\n",
    "        #Gray Scale \n",
    "        images.append(cv2.cvtColor(cv2.resize(cv2.imread(i),(IMG_SIZE,IMG_SIZE)), cv2.COLOR_BGR2GRAY))\n",
    "    return images \n",
    "\n",
    "#X_train array of images with values between 0 and 1\n",
    "X_train = np.array(get_imgs(paths)).astype(np.float32)\n",
    "#reshaped X train and shifted pixzel values between -1 and 1 for tanh \n",
    "X_train_dcgan = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1) * 2. - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((BATCH_SIZE,1,1,1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "class WGANGP():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_discriminator = 5\n",
    "        optimizer = RMSprop(learning_rate=0.00005)\n",
    "\n",
    "        # Build the generator and discriminator\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the discriminator\n",
    "        #-------------------------------\n",
    "\n",
    "        # Freeze generator's layers while training discriminator\n",
    "        self.generator.trainable = False\n",
    "\n",
    "        # Image input (real sample)\n",
    "        real_img = Input(shape=self.img_shape)\n",
    "\n",
    "        # Noise input\n",
    "        z_disc = Input(shape=(self.latent_dim,))\n",
    "        # Generate image based of noise (fake sample)\n",
    "        fake_img = self.generator(z_disc)\n",
    "\n",
    "        # Discriminator determines validity of the real and fake images\n",
    "        fake = self.discriminator(fake_img)\n",
    "        valid = self.discriminator(real_img)\n",
    "\n",
    "        # Construct weighted average between real and fake images\n",
    "        interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n",
    "        # Determine validity of weighted sample\n",
    "        validity_interpolated = self.discriminator(interpolated_img)\n",
    "\n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
    "                          averaged_samples=interpolated_img)\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "        self.discriminator_model = Model(inputs=[real_img, z_disc],\n",
    "                            outputs=[valid, fake, validity_interpolated])\n",
    "        self.discriminator_model.compile(loss=[self.wasserstein_loss,\n",
    "                                              self.wasserstein_loss,\n",
    "                                              partial_gp_loss],\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_weights=[1, 1, 10])\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "\n",
    "        # For the generator we freeze the discriminator's layers\n",
    "        self.discriminator.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        # Sampled noise for input to generator\n",
    "        z_gen = Input(shape=(self.latent_dim,))\n",
    "        # Generate images based of noise\n",
    "        img = self.generator(z_gen)\n",
    "        # Discriminator determines validity\n",
    "        valid = self.discriminator(img)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model(z_gen, valid)\n",
    "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "    \n",
    "\n",
    "    \n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 32* 32, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((32,32, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=5, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=5, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        \"\"\"model = Sequential()\n",
    "        model.add(Dense(128 * 32* 32, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((32,32, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\"\"\"\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(16, kernel_size=5, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=5, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        \"\"\"model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=[128, 128, 1], padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\"\"\"\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        X_train = X_train_dcgan\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        #X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        #X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake =  np.ones((batch_size, 1))\n",
    "        dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for _ in range(self.n_discriminator):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                # Sample generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                # Train the discriminator\n",
    "                d_loss = self.discriminator_model.train_on_batch([imgs, noise],\n",
    "                                                                [valid, fake, dummy])\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.generator_model.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 1 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"GAN_images/generated_%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 131072)            13238272  \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 64, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 128)       409728    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 64, 64, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 128, 128, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 128, 128, 64)      204864    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 128, 128, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 128, 128, 1)       1025      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 128, 128, 1)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,854,657\n",
      "Trainable params: 13,854,273\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_17 (Conv2D)          (None, 64, 64, 16)        416       \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 64, 64, 16)        0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64, 64, 16)        0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 32, 32, 32)        12832     \n",
      "                                                                 \n",
      " zero_padding2d_2 (ZeroPaddi  (None, 33, 33, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 33, 33, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 33, 33, 32)        0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 33, 33, 32)        0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 17, 17, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 17, 17, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 17, 17, 64)        0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 17, 17, 64)        0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 17, 17, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 17, 17, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 17, 17, 128)       0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 17, 17, 128)       0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 36992)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 36993     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,489\n",
      "Trainable params: 143,041\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "0 [D loss: 888500.062500] [G loss: -0.312784]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nprim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: 96156.039062] [G loss: -0.040860]\n",
      "2 [D loss: 177705.046875] [G loss: -0.004781]\n",
      "3 [D loss: 148299.000000] [G loss: -0.103721]\n",
      "4 [D loss: 1286735.625000] [G loss: 0.035073]\n",
      "5 [D loss: 3189149.000000] [G loss: 0.516573]\n",
      "6 [D loss: 232724.890625] [G loss: 0.866434]\n",
      "7 [D loss: 975341.687500] [G loss: 0.136553]\n",
      "8 [D loss: 2552235.500000] [G loss: 0.828091]\n",
      "9 [D loss: 4744849.000000] [G loss: 0.965784]\n",
      "10 [D loss: 516317.343750] [G loss: 0.778803]\n",
      "11 [D loss: 58405.738281] [G loss: 1.266445]\n",
      "12 [D loss: 3806865.000000] [G loss: 1.131162]\n",
      "13 [D loss: 917519.937500] [G loss: 1.631450]\n",
      "14 [D loss: 1490713.500000] [G loss: 1.851853]\n",
      "15 [D loss: 4241451.000000] [G loss: 1.682272]\n",
      "16 [D loss: 2775915.000000] [G loss: 1.923017]\n",
      "17 [D loss: 1245162.875000] [G loss: 1.941568]\n",
      "18 [D loss: 820025.125000] [G loss: 2.330402]\n",
      "19 [D loss: 1606623.125000] [G loss: 3.034023]\n",
      "20 [D loss: 1343355.500000] [G loss: 2.897003]\n",
      "21 [D loss: 16064.024414] [G loss: 2.820169]\n",
      "22 [D loss: 595668.750000] [G loss: 2.962998]\n",
      "23 [D loss: 24580.250000] [G loss: 2.477170]\n",
      "24 [D loss: 1202761.500000] [G loss: 3.122055]\n",
      "25 [D loss: 30387.646484] [G loss: 3.122594]\n",
      "26 [D loss: 6005811.500000] [G loss: 3.104849]\n",
      "27 [D loss: 174567.593750] [G loss: 2.682369]\n",
      "28 [D loss: 564944.187500] [G loss: 3.242588]\n",
      "29 [D loss: 520907.156250] [G loss: 3.357752]\n",
      "30 [D loss: 432688.343750] [G loss: 3.148341]\n",
      "31 [D loss: 333995.187500] [G loss: 3.425931]\n",
      "32 [D loss: 811464.687500] [G loss: 3.208799]\n",
      "33 [D loss: 574673.812500] [G loss: 3.181149]\n",
      "34 [D loss: 1654072.125000] [G loss: 3.034240]\n",
      "35 [D loss: 136018.718750] [G loss: 3.158669]\n",
      "36 [D loss: 280329.531250] [G loss: 3.402195]\n",
      "37 [D loss: 767701.437500] [G loss: 3.645024]\n",
      "38 [D loss: 155741.437500] [G loss: 2.974139]\n",
      "39 [D loss: 894571.062500] [G loss: 3.548952]\n",
      "40 [D loss: 577853.500000] [G loss: 3.410488]\n",
      "41 [D loss: 1409398.875000] [G loss: 3.865661]\n",
      "42 [D loss: 3885424.250000] [G loss: 3.839360]\n",
      "43 [D loss: 416276.437500] [G loss: 3.894515]\n",
      "44 [D loss: 56624.429688] [G loss: 4.124521]\n",
      "45 [D loss: 1460502.750000] [G loss: 4.243326]\n",
      "46 [D loss: 218721.171875] [G loss: 4.560208]\n",
      "47 [D loss: 1014117.000000] [G loss: 4.585223]\n",
      "48 [D loss: 64428.230469] [G loss: 4.655301]\n",
      "49 [D loss: 141006.593750] [G loss: 4.420989]\n",
      "50 [D loss: 1838315.875000] [G loss: 5.097409]\n",
      "51 [D loss: 463777.000000] [G loss: 4.963266]\n",
      "52 [D loss: 11988.367188] [G loss: 4.694416]\n",
      "53 [D loss: 1149016.750000] [G loss: 5.140755]\n",
      "54 [D loss: 2658796.000000] [G loss: 5.880274]\n",
      "55 [D loss: 1412506.375000] [G loss: 5.213940]\n",
      "56 [D loss: 592359.437500] [G loss: 5.360401]\n",
      "57 [D loss: 532629.625000] [G loss: 5.877540]\n",
      "58 [D loss: 21057.332031] [G loss: 5.372084]\n",
      "59 [D loss: 15467.659180] [G loss: 5.632963]\n",
      "60 [D loss: 412844.437500] [G loss: 5.565907]\n",
      "61 [D loss: 23136.306641] [G loss: 5.587502]\n",
      "62 [D loss: 2005536.000000] [G loss: 6.169023]\n",
      "63 [D loss: 331911.000000] [G loss: 5.868897]\n",
      "64 [D loss: 13170.757812] [G loss: 5.874518]\n",
      "65 [D loss: 102034.476562] [G loss: 6.271436]\n",
      "66 [D loss: 203061.531250] [G loss: 6.045314]\n",
      "67 [D loss: 41667.179688] [G loss: 5.368285]\n",
      "68 [D loss: 1405881.125000] [G loss: 7.180907]\n",
      "69 [D loss: 206639.531250] [G loss: 7.096520]\n",
      "70 [D loss: 121777.632812] [G loss: 5.677370]\n",
      "71 [D loss: 176124.343750] [G loss: 5.481649]\n",
      "72 [D loss: 633189.000000] [G loss: 4.334311]\n",
      "73 [D loss: 807870.125000] [G loss: 5.576231]\n",
      "74 [D loss: 1023830.187500] [G loss: 5.102298]\n",
      "75 [D loss: 502730.093750] [G loss: 3.627739]\n",
      "76 [D loss: 348872.406250] [G loss: 4.041811]\n",
      "77 [D loss: 706146.000000] [G loss: 3.348291]\n",
      "78 [D loss: 2527465.750000] [G loss: 2.943800]\n",
      "79 [D loss: 1533735.750000] [G loss: 2.266659]\n",
      "80 [D loss: 61089.332031] [G loss: 0.763740]\n",
      "81 [D loss: 38559.062500] [G loss: 0.633297]\n",
      "82 [D loss: 299457.781250] [G loss: 0.197310]\n",
      "83 [D loss: 9286191.000000] [G loss: -0.252468]\n",
      "84 [D loss: 4846228.500000] [G loss: -0.068658]\n",
      "85 [D loss: 4095757.750000] [G loss: -1.633639]\n",
      "86 [D loss: 233093.671875] [G loss: -1.826076]\n",
      "87 [D loss: 247502.312500] [G loss: -1.863604]\n",
      "88 [D loss: 933863.062500] [G loss: -2.984800]\n",
      "89 [D loss: 1001471.625000] [G loss: -2.735788]\n",
      "90 [D loss: 1412578.250000] [G loss: -4.084198]\n",
      "91 [D loss: 689289.000000] [G loss: -3.843436]\n",
      "92 [D loss: 1720000.125000] [G loss: -4.864797]\n",
      "93 [D loss: 1650611.125000] [G loss: -4.159731]\n",
      "94 [D loss: 6017128.500000] [G loss: -5.363523]\n",
      "95 [D loss: 2204770.000000] [G loss: -5.368320]\n",
      "96 [D loss: 13631068.000000] [G loss: -5.872701]\n",
      "97 [D loss: 4934926.500000] [G loss: -5.830064]\n",
      "98 [D loss: 2203646.000000] [G loss: -5.454958]\n",
      "99 [D loss: 1433822.375000] [G loss: -6.678622]\n",
      "100 [D loss: 432417.312500] [G loss: -6.012245]\n",
      "101 [D loss: 5242565.500000] [G loss: -5.728962]\n",
      "102 [D loss: 1770600.375000] [G loss: -7.207788]\n",
      "103 [D loss: 6391996.000000] [G loss: -7.735307]\n",
      "104 [D loss: 4192031.250000] [G loss: -7.894615]\n",
      "105 [D loss: 1185032.875000] [G loss: -6.816139]\n",
      "106 [D loss: 2403522.250000] [G loss: -7.652072]\n",
      "107 [D loss: 1667735.250000] [G loss: -9.136677]\n",
      "108 [D loss: 816257.312500] [G loss: -8.913013]\n",
      "109 [D loss: 2172572.000000] [G loss: -7.871283]\n",
      "110 [D loss: 1199481.125000] [G loss: -8.335785]\n",
      "111 [D loss: 3605402.500000] [G loss: -10.002559]\n",
      "112 [D loss: 1345265.625000] [G loss: -8.924304]\n",
      "113 [D loss: 1505143.750000] [G loss: -9.099307]\n",
      "114 [D loss: 3933105.750000] [G loss: -8.750377]\n",
      "115 [D loss: 2401385.000000] [G loss: -9.419296]\n",
      "116 [D loss: 367886.031250] [G loss: -8.772645]\n",
      "117 [D loss: 1578831.875000] [G loss: -11.031811]\n",
      "118 [D loss: 1225943.625000] [G loss: -8.825293]\n",
      "119 [D loss: 1039684.187500] [G loss: -9.198783]\n",
      "120 [D loss: 1518034.125000] [G loss: -10.986744]\n",
      "121 [D loss: 687425.000000] [G loss: -9.183781]\n",
      "122 [D loss: 703427.500000] [G loss: -8.383353]\n",
      "123 [D loss: 4116638.750000] [G loss: -11.287369]\n",
      "124 [D loss: 3102092.500000] [G loss: -11.425113]\n",
      "125 [D loss: 234939.968750] [G loss: -11.770697]\n",
      "126 [D loss: 93837.335938] [G loss: -11.704870]\n",
      "127 [D loss: 2143115.500000] [G loss: -10.427729]\n",
      "128 [D loss: 619224.062500] [G loss: -15.650297]\n",
      "129 [D loss: 419203.906250] [G loss: -11.833107]\n",
      "130 [D loss: 1198540.625000] [G loss: -11.705851]\n",
      "131 [D loss: 1086746.250000] [G loss: -11.052238]\n",
      "132 [D loss: 4234152.500000] [G loss: -12.674051]\n",
      "133 [D loss: 1627212.625000] [G loss: -14.023794]\n",
      "134 [D loss: 512833.468750] [G loss: -11.893599]\n",
      "135 [D loss: 884619.375000] [G loss: -13.305700]\n",
      "136 [D loss: 2181005.250000] [G loss: -12.802702]\n",
      "137 [D loss: 1017833.687500] [G loss: -12.520973]\n",
      "138 [D loss: 1893778.000000] [G loss: -12.105609]\n",
      "139 [D loss: 1383339.000000] [G loss: -12.931887]\n",
      "140 [D loss: 793006.812500] [G loss: -12.472368]\n",
      "141 [D loss: 2095628.500000] [G loss: -12.097469]\n",
      "142 [D loss: 672250.062500] [G loss: -13.059646]\n",
      "143 [D loss: 211209.953125] [G loss: -12.295744]\n",
      "144 [D loss: 504283.312500] [G loss: -13.399008]\n",
      "145 [D loss: 729203.312500] [G loss: -14.779451]\n",
      "146 [D loss: 1614229.375000] [G loss: -11.643162]\n",
      "147 [D loss: 479929.187500] [G loss: -12.588519]\n",
      "148 [D loss: 188067.218750] [G loss: -11.673919]\n",
      "149 [D loss: 1171480.625000] [G loss: -11.863901]\n",
      "150 [D loss: 1100916.125000] [G loss: -12.286112]\n",
      "151 [D loss: 751786.750000] [G loss: -11.837654]\n",
      "152 [D loss: 563861.312500] [G loss: -11.484413]\n",
      "153 [D loss: 1424201.250000] [G loss: -10.666838]\n",
      "154 [D loss: 6011926.000000] [G loss: -10.035526]\n",
      "155 [D loss: 1863361.000000] [G loss: -10.062937]\n",
      "156 [D loss: 2150469.500000] [G loss: -12.540709]\n",
      "157 [D loss: 1310323.875000] [G loss: -12.099748]\n",
      "158 [D loss: 381483.437500] [G loss: -9.979807]\n",
      "159 [D loss: 124198.976562] [G loss: -13.158705]\n",
      "160 [D loss: 1291379.250000] [G loss: -14.492781]\n",
      "161 [D loss: 439214.000000] [G loss: -12.967203]\n",
      "162 [D loss: 3462177.500000] [G loss: -11.131275]\n",
      "163 [D loss: 323798.531250] [G loss: -12.218142]\n",
      "164 [D loss: 593819.937500] [G loss: -10.200568]\n",
      "165 [D loss: 1205417.500000] [G loss: -10.434719]\n",
      "166 [D loss: 485206.593750] [G loss: -10.503573]\n",
      "167 [D loss: 3571564.250000] [G loss: -9.113089]\n",
      "168 [D loss: 515718.687500] [G loss: -10.845041]\n",
      "169 [D loss: 132263.765625] [G loss: -10.095648]\n",
      "170 [D loss: 1943225.625000] [G loss: -11.604718]\n",
      "171 [D loss: 1083665.750000] [G loss: -7.978320]\n",
      "172 [D loss: 625471.500000] [G loss: -8.204008]\n",
      "173 [D loss: 1874678.125000] [G loss: -5.612303]\n",
      "174 [D loss: 475099.031250] [G loss: -9.642927]\n",
      "175 [D loss: 717496.375000] [G loss: -9.410040]\n",
      "176 [D loss: 425433.687500] [G loss: -8.474706]\n",
      "177 [D loss: 463664.875000] [G loss: -8.957819]\n",
      "178 [D loss: 1068178.250000] [G loss: -6.089664]\n",
      "179 [D loss: 282026.500000] [G loss: -6.122835]\n",
      "180 [D loss: 636382.125000] [G loss: -7.385155]\n",
      "181 [D loss: 81479.601562] [G loss: -5.226008]\n",
      "182 [D loss: 675521.937500] [G loss: -5.139975]\n",
      "183 [D loss: 487038.000000] [G loss: -5.347712]\n",
      "184 [D loss: 243866.640625] [G loss: -5.928706]\n",
      "185 [D loss: 242484.734375] [G loss: -1.654784]\n",
      "186 [D loss: 20037.373047] [G loss: -1.563410]\n",
      "187 [D loss: 10392.726562] [G loss: -0.965215]\n",
      "188 [D loss: 143558.843750] [G loss: -3.048445]\n",
      "189 [D loss: 240786.140625] [G loss: -4.182608]\n",
      "190 [D loss: 589967.687500] [G loss: -4.309707]\n",
      "191 [D loss: 58613.132812] [G loss: -3.204558]\n",
      "192 [D loss: 86819.406250] [G loss: -3.615786]\n",
      "193 [D loss: 59412.359375] [G loss: 0.409764]\n",
      "194 [D loss: 67811.210938] [G loss: 0.260240]\n",
      "195 [D loss: 26062.001953] [G loss: -2.621945]\n",
      "196 [D loss: 40626.917969] [G loss: -1.397414]\n",
      "197 [D loss: 219808.546875] [G loss: 0.330905]\n",
      "198 [D loss: 82143.835938] [G loss: 4.275012]\n",
      "199 [D loss: 33185.535156] [G loss: 2.051155]\n",
      "200 [D loss: 11989.559570] [G loss: 5.719081]\n",
      "201 [D loss: 4746.440430] [G loss: 12.196629]\n",
      "202 [D loss: 63120.640625] [G loss: 17.150724]\n",
      "203 [D loss: 42804.164062] [G loss: 9.343731]\n",
      "204 [D loss: 125392.710938] [G loss: 13.810122]\n",
      "205 [D loss: 11672.369141] [G loss: 11.788912]\n",
      "206 [D loss: 19502.195312] [G loss: 18.035040]\n",
      "207 [D loss: 24474.582031] [G loss: 14.335971]\n",
      "208 [D loss: 63064.648438] [G loss: 17.000511]\n",
      "209 [D loss: 62489.609375] [G loss: 17.487467]\n",
      "210 [D loss: 3832.252197] [G loss: 21.459562]\n",
      "211 [D loss: 12243.689453] [G loss: 20.843121]\n",
      "212 [D loss: 2710.422363] [G loss: 25.672070]\n",
      "213 [D loss: 8711.592773] [G loss: 26.258739]\n",
      "214 [D loss: 17583.388672] [G loss: 28.953400]\n",
      "215 [D loss: 2833.648682] [G loss: 28.879993]\n",
      "216 [D loss: 20352.404297] [G loss: 33.176838]\n",
      "217 [D loss: 51575.484375] [G loss: 30.649038]\n",
      "218 [D loss: 1692.520630] [G loss: 33.415775]\n",
      "219 [D loss: 52112.910156] [G loss: 29.057871]\n",
      "220 [D loss: 918.672546] [G loss: 36.719471]\n",
      "221 [D loss: 15577.621094] [G loss: 38.097065]\n",
      "222 [D loss: 2216.934326] [G loss: 37.471928]\n",
      "223 [D loss: 17093.128906] [G loss: 46.676842]\n",
      "224 [D loss: 257246.171875] [G loss: 38.951363]\n",
      "225 [D loss: 4604.110352] [G loss: 41.211121]\n",
      "226 [D loss: 10355.614258] [G loss: 38.351593]\n",
      "227 [D loss: 1620.168335] [G loss: 46.211639]\n",
      "228 [D loss: 41327.574219] [G loss: 36.796066]\n",
      "229 [D loss: 4122.483398] [G loss: 39.390015]\n",
      "230 [D loss: 5913.859863] [G loss: 41.321018]\n",
      "231 [D loss: 31082.400391] [G loss: 44.356186]\n",
      "232 [D loss: 13496.834961] [G loss: 42.030144]\n",
      "233 [D loss: 51032.378906] [G loss: 42.629845]\n",
      "234 [D loss: 16979.988281] [G loss: 46.369019]\n",
      "235 [D loss: 38813.308594] [G loss: 44.156372]\n",
      "236 [D loss: 9907.927734] [G loss: 49.724007]\n",
      "237 [D loss: 4533.702637] [G loss: 59.651726]\n",
      "238 [D loss: 2738.444580] [G loss: 57.956284]\n",
      "239 [D loss: 2989.518066] [G loss: 54.242283]\n",
      "240 [D loss: -448.593140] [G loss: 62.084972]\n",
      "241 [D loss: -703.556580] [G loss: 59.442635]\n",
      "242 [D loss: -622.285217] [G loss: 53.177708]\n",
      "243 [D loss: 3003.231689] [G loss: 51.292889]\n",
      "244 [D loss: 31269.726562] [G loss: 46.355328]\n",
      "245 [D loss: 7903.719238] [G loss: 50.883167]\n",
      "246 [D loss: 12225.862305] [G loss: 45.633156]\n",
      "247 [D loss: 3503.787842] [G loss: 50.517292]\n",
      "248 [D loss: 57045.105469] [G loss: 43.675896]\n",
      "249 [D loss: 1792.789429] [G loss: 46.076855]\n",
      "250 [D loss: -18.651611] [G loss: 46.385845]\n",
      "251 [D loss: 875.255859] [G loss: 48.696423]\n",
      "252 [D loss: 1326.638062] [G loss: 50.774517]\n",
      "253 [D loss: 2334.702637] [G loss: 45.935955]\n",
      "254 [D loss: 640.840210] [G loss: 51.849289]\n",
      "255 [D loss: 2093.836670] [G loss: 54.027008]\n",
      "256 [D loss: -1059.916138] [G loss: 48.317986]\n",
      "257 [D loss: 13192.840820] [G loss: 52.218533]\n",
      "258 [D loss: 5275.189941] [G loss: 50.689671]\n",
      "259 [D loss: 1200.218750] [G loss: 45.405930]\n",
      "260 [D loss: 5640.906738] [G loss: 45.798965]\n",
      "261 [D loss: 2896.052246] [G loss: 41.718330]\n",
      "262 [D loss: 266.359741] [G loss: 32.405930]\n",
      "263 [D loss: -778.666199] [G loss: 49.570778]\n",
      "264 [D loss: 11773.358398] [G loss: 31.035368]\n",
      "265 [D loss: 3013.236328] [G loss: 41.870461]\n",
      "266 [D loss: 2100.681885] [G loss: 36.925964]\n",
      "267 [D loss: -399.360474] [G loss: 55.863800]\n",
      "268 [D loss: -704.257202] [G loss: 48.810726]\n",
      "269 [D loss: 796.264160] [G loss: 38.743752]\n",
      "270 [D loss: -183.141724] [G loss: 53.324718]\n",
      "271 [D loss: 846.373047] [G loss: 49.026436]\n",
      "272 [D loss: 1449.367676] [G loss: 38.011444]\n",
      "273 [D loss: 2107.363770] [G loss: 31.221455]\n",
      "274 [D loss: 1090.349487] [G loss: 44.410217]\n",
      "275 [D loss: -131.579834] [G loss: 41.734215]\n",
      "276 [D loss: 26030.876953] [G loss: 52.264015]\n",
      "277 [D loss: 1390.708252] [G loss: 47.170769]\n",
      "278 [D loss: 3833.554443] [G loss: 46.032227]\n",
      "279 [D loss: -1305.023926] [G loss: 53.543663]\n",
      "280 [D loss: -550.520264] [G loss: 48.979858]\n",
      "281 [D loss: -882.259033] [G loss: 51.216999]\n",
      "282 [D loss: 1358.392700] [G loss: 42.788651]\n",
      "283 [D loss: -604.613525] [G loss: 51.858025]\n",
      "284 [D loss: 1247.402832] [G loss: 56.727699]\n",
      "285 [D loss: -592.252808] [G loss: 46.793736]\n",
      "286 [D loss: -1559.098145] [G loss: 45.752327]\n",
      "287 [D loss: 620.820801] [G loss: 53.263790]\n",
      "288 [D loss: -973.136780] [G loss: 57.837196]\n",
      "289 [D loss: -1266.086548] [G loss: 42.622272]\n",
      "290 [D loss: -1645.851562] [G loss: 54.424938]\n",
      "291 [D loss: -385.002319] [G loss: 41.609489]\n",
      "292 [D loss: -1485.051880] [G loss: 58.104477]\n",
      "293 [D loss: 7077.199219] [G loss: 49.290192]\n",
      "294 [D loss: -1702.446777] [G loss: 58.103676]\n",
      "295 [D loss: -1534.015869] [G loss: 62.719521]\n",
      "296 [D loss: -1674.755493] [G loss: 59.195374]\n",
      "297 [D loss: -1536.907349] [G loss: 49.621681]\n",
      "298 [D loss: -1491.034668] [G loss: 51.605667]\n",
      "299 [D loss: -1419.885010] [G loss: 64.147858]\n",
      "300 [D loss: 2675.024414] [G loss: 47.245159]\n",
      "301 [D loss: -1226.368408] [G loss: 49.740982]\n",
      "302 [D loss: -428.229492] [G loss: 52.059845]\n",
      "303 [D loss: -1596.754150] [G loss: 42.738724]\n",
      "304 [D loss: -1784.100830] [G loss: 51.933018]\n",
      "305 [D loss: -499.892822] [G loss: 41.026012]\n",
      "306 [D loss: -1526.109497] [G loss: 49.459435]\n",
      "307 [D loss: -1334.873535] [G loss: 46.730877]\n",
      "308 [D loss: -1129.234863] [G loss: 54.105453]\n",
      "309 [D loss: -1716.738281] [G loss: 47.812374]\n",
      "310 [D loss: -1666.372803] [G loss: 43.583534]\n",
      "311 [D loss: -352.586182] [G loss: 42.444984]\n",
      "312 [D loss: -528.992310] [G loss: 35.243217]\n",
      "313 [D loss: 8835.345703] [G loss: 38.710178]\n",
      "314 [D loss: -1794.931519] [G loss: 46.922997]\n",
      "315 [D loss: -1772.734619] [G loss: 45.824181]\n",
      "316 [D loss: -1604.368286] [G loss: 47.776688]\n",
      "317 [D loss: 632.929199] [G loss: 50.833778]\n",
      "318 [D loss: -1480.384521] [G loss: 62.927265]\n",
      "319 [D loss: -1659.239136] [G loss: 64.489288]\n",
      "320 [D loss: -883.860229] [G loss: 28.848347]\n",
      "321 [D loss: -1935.867432] [G loss: 49.542377]\n",
      "322 [D loss: -949.106567] [G loss: 25.320507]\n",
      "323 [D loss: -1714.207764] [G loss: 51.894028]\n",
      "324 [D loss: -119.855957] [G loss: 55.376629]\n",
      "325 [D loss: -1170.660645] [G loss: 51.635586]\n",
      "326 [D loss: -1518.046631] [G loss: 49.635880]\n",
      "327 [D loss: 239.130859] [G loss: 37.707542]\n",
      "328 [D loss: -1966.658203] [G loss: 50.177597]\n",
      "329 [D loss: -1952.227661] [G loss: 57.553726]\n",
      "330 [D loss: -1992.332275] [G loss: 30.326408]\n",
      "331 [D loss: -1504.066895] [G loss: 34.679504]\n",
      "332 [D loss: -1420.980347] [G loss: 44.670143]\n",
      "333 [D loss: -1970.715576] [G loss: 39.222313]\n",
      "334 [D loss: -1728.523926] [G loss: 38.311665]\n",
      "335 [D loss: -1329.793457] [G loss: 39.542007]\n",
      "336 [D loss: -2004.558716] [G loss: 37.950329]\n",
      "337 [D loss: -1932.565552] [G loss: 40.761871]\n",
      "338 [D loss: -1762.021484] [G loss: 46.029369]\n",
      "339 [D loss: -1286.946777] [G loss: 29.337742]\n",
      "340 [D loss: -2050.420898] [G loss: 45.007442]\n",
      "341 [D loss: -1767.040161] [G loss: 19.020573]\n",
      "342 [D loss: -2168.839111] [G loss: -0.718917]\n",
      "343 [D loss: -1811.484863] [G loss: 13.936379]\n",
      "344 [D loss: -2042.942627] [G loss: 36.006107]\n",
      "345 [D loss: -1984.874023] [G loss: 25.609715]\n",
      "346 [D loss: -2024.715332] [G loss: 35.811203]\n",
      "347 [D loss: -1645.514160] [G loss: 31.677759]\n",
      "348 [D loss: 246.751709] [G loss: 33.731422]\n",
      "349 [D loss: -2283.135498] [G loss: 31.823250]\n",
      "350 [D loss: -1587.716675] [G loss: 46.834236]\n",
      "351 [D loss: -1955.566895] [G loss: 5.498291]\n",
      "352 [D loss: 837.063232] [G loss: 8.983141]\n",
      "353 [D loss: -2103.809814] [G loss: 10.360618]\n",
      "354 [D loss: -2046.922607] [G loss: 18.970596]\n",
      "355 [D loss: -2307.482422] [G loss: 14.923636]\n",
      "356 [D loss: -1897.898804] [G loss: -11.462116]\n",
      "357 [D loss: -2048.032471] [G loss: 21.470966]\n",
      "358 [D loss: -2177.607178] [G loss: 10.157648]\n",
      "359 [D loss: -1331.127075] [G loss: 31.196350]\n",
      "360 [D loss: -2210.581055] [G loss: 22.473133]\n",
      "361 [D loss: -2330.170898] [G loss: 34.205292]\n",
      "362 [D loss: -1687.860352] [G loss: -9.639524]\n",
      "363 [D loss: -2193.586426] [G loss: -3.249254]\n",
      "364 [D loss: -2446.217529] [G loss: -3.135186]\n",
      "365 [D loss: -2456.888916] [G loss: -3.685347]\n",
      "366 [D loss: -2280.261475] [G loss: -10.010312]\n",
      "367 [D loss: -2383.974121] [G loss: -10.071432]\n",
      "368 [D loss: -2438.807617] [G loss: -2.930361]\n",
      "369 [D loss: -2393.081787] [G loss: -14.338986]\n",
      "370 [D loss: -2306.659180] [G loss: -20.940573]\n",
      "371 [D loss: -1721.287354] [G loss: -28.109715]\n",
      "372 [D loss: -2285.196289] [G loss: -51.537476]\n",
      "373 [D loss: -2388.484863] [G loss: -28.949028]\n",
      "374 [D loss: -2169.742432] [G loss: -17.853434]\n",
      "375 [D loss: -2457.778320] [G loss: -32.257561]\n",
      "376 [D loss: -2546.830078] [G loss: -48.135151]\n",
      "377 [D loss: -2300.197266] [G loss: -76.940216]\n",
      "378 [D loss: -2448.070312] [G loss: -54.489243]\n",
      "379 [D loss: -2333.050049] [G loss: -67.653748]\n",
      "380 [D loss: -2456.618896] [G loss: -70.267609]\n",
      "381 [D loss: -2601.898193] [G loss: -77.721924]\n",
      "382 [D loss: -2613.731445] [G loss: -56.453434]\n",
      "383 [D loss: -2483.536377] [G loss: -96.490112]\n",
      "384 [D loss: -2371.265625] [G loss: -73.757370]\n",
      "385 [D loss: -2340.669434] [G loss: -113.206932]\n",
      "386 [D loss: -2686.014648] [G loss: -82.800316]\n",
      "387 [D loss: -2033.818604] [G loss: -80.719856]\n",
      "388 [D loss: -2587.283447] [G loss: -87.919327]\n",
      "389 [D loss: -2493.695801] [G loss: -86.135132]\n",
      "390 [D loss: -2588.376709] [G loss: -62.756325]\n",
      "391 [D loss: -2731.511230] [G loss: -74.353287]\n",
      "392 [D loss: -2740.270996] [G loss: -80.795013]\n",
      "393 [D loss: -2534.121094] [G loss: -109.748619]\n",
      "394 [D loss: -2531.457520] [G loss: -143.465759]\n",
      "395 [D loss: -1862.649902] [G loss: -105.850327]\n",
      "396 [D loss: -2767.919678] [G loss: -88.565887]\n",
      "397 [D loss: -2648.275391] [G loss: -137.915634]\n",
      "398 [D loss: -2785.475098] [G loss: -119.960556]\n",
      "399 [D loss: -2689.489014] [G loss: -146.991821]\n",
      "400 [D loss: -2704.941895] [G loss: -108.995941]\n",
      "401 [D loss: -2194.140137] [G loss: -111.617859]\n",
      "402 [D loss: -1664.421265] [G loss: -129.066345]\n",
      "403 [D loss: -2659.013184] [G loss: -163.288086]\n",
      "404 [D loss: -2629.556885] [G loss: -155.502075]\n",
      "405 [D loss: -2707.060791] [G loss: -124.002769]\n",
      "406 [D loss: -2802.042725] [G loss: -141.431290]\n",
      "407 [D loss: -2585.434570] [G loss: -147.899094]\n",
      "408 [D loss: -2066.148438] [G loss: -166.468475]\n",
      "409 [D loss: -2906.736816] [G loss: -143.446060]\n",
      "410 [D loss: -2613.939453] [G loss: -175.421021]\n",
      "411 [D loss: -1268.821045] [G loss: -171.544922]\n",
      "412 [D loss: 3.576660] [G loss: -177.939575]\n",
      "413 [D loss: -2370.717285] [G loss: -151.109344]\n",
      "414 [D loss: -2491.477051] [G loss: -177.993286]\n",
      "415 [D loss: -2865.685791] [G loss: -129.017090]\n",
      "416 [D loss: -2931.147217] [G loss: -174.716782]\n",
      "417 [D loss: -2120.751465] [G loss: -186.184906]\n",
      "418 [D loss: -2923.377686] [G loss: -196.041504]\n",
      "419 [D loss: -2368.901367] [G loss: -157.861664]\n",
      "420 [D loss: 3592.389648] [G loss: -186.048218]\n",
      "421 [D loss: -2436.291016] [G loss: -208.321991]\n",
      "422 [D loss: -3051.164551] [G loss: -198.020966]\n",
      "423 [D loss: -2821.492188] [G loss: -205.556259]\n",
      "424 [D loss: -1964.703125] [G loss: -193.845123]\n",
      "425 [D loss: -2378.172119] [G loss: -199.354126]\n",
      "426 [D loss: -2120.163086] [G loss: -212.448212]\n",
      "427 [D loss: -3016.436523] [G loss: -189.993515]\n",
      "428 [D loss: -3028.487061] [G loss: -211.299362]\n",
      "429 [D loss: -3047.568604] [G loss: -215.206299]\n",
      "430 [D loss: -2488.280029] [G loss: -191.772888]\n",
      "431 [D loss: -2962.093262] [G loss: -226.021301]\n",
      "432 [D loss: -550.191895] [G loss: -224.464142]\n",
      "433 [D loss: -2369.407227] [G loss: -257.213562]\n",
      "434 [D loss: -2882.100098] [G loss: -226.680573]\n",
      "435 [D loss: -2545.415527] [G loss: -232.224487]\n",
      "436 [D loss: -3219.747559] [G loss: -226.844452]\n",
      "437 [D loss: -2710.030518] [G loss: -228.196625]\n",
      "438 [D loss: -3276.311035] [G loss: -209.564240]\n",
      "439 [D loss: -2768.723877] [G loss: -209.508667]\n",
      "440 [D loss: -3076.017090] [G loss: -241.958557]\n",
      "441 [D loss: -3215.553467] [G loss: -246.307953]\n",
      "442 [D loss: -3176.270752] [G loss: -252.671875]\n",
      "443 [D loss: -3060.094238] [G loss: -210.379395]\n",
      "444 [D loss: -2891.963135] [G loss: -248.732361]\n",
      "445 [D loss: -3015.522705] [G loss: -230.792450]\n",
      "446 [D loss: -3139.889404] [G loss: -213.156281]\n",
      "447 [D loss: -3329.676025] [G loss: -281.528137]\n",
      "448 [D loss: -2468.860596] [G loss: -219.789581]\n",
      "449 [D loss: -2886.715576] [G loss: -220.540192]\n",
      "450 [D loss: -3244.344238] [G loss: -267.467926]\n",
      "451 [D loss: -3374.187012] [G loss: -259.127319]\n",
      "452 [D loss: -3405.107666] [G loss: -248.458298]\n",
      "453 [D loss: -3350.465820] [G loss: -238.372894]\n",
      "454 [D loss: -3146.325195] [G loss: -253.480469]\n",
      "455 [D loss: -3372.823975] [G loss: -225.301010]\n",
      "456 [D loss: -3391.182617] [G loss: -277.203400]\n",
      "457 [D loss: -2078.476562] [G loss: -306.206573]\n",
      "458 [D loss: -3210.313965] [G loss: -242.790466]\n",
      "459 [D loss: -3382.725830] [G loss: -215.871033]\n",
      "460 [D loss: -3394.312988] [G loss: -258.546478]\n",
      "461 [D loss: -3434.569336] [G loss: -261.769379]\n",
      "462 [D loss: -3348.202393] [G loss: -271.862488]\n",
      "463 [D loss: -3014.125732] [G loss: -278.203552]\n",
      "464 [D loss: -2787.373535] [G loss: -263.015259]\n",
      "465 [D loss: -3441.522949] [G loss: -274.289734]\n",
      "466 [D loss: -2646.716064] [G loss: -284.518463]\n",
      "467 [D loss: -3471.829834] [G loss: -269.125366]\n",
      "468 [D loss: -3355.252930] [G loss: -277.805542]\n",
      "469 [D loss: -3452.041504] [G loss: -226.002136]\n",
      "470 [D loss: -3381.963867] [G loss: -215.731598]\n",
      "471 [D loss: -2731.366699] [G loss: -256.024292]\n",
      "472 [D loss: -3687.579590] [G loss: -257.083008]\n",
      "473 [D loss: -3275.358643] [G loss: -295.091919]\n",
      "474 [D loss: -3594.216064] [G loss: -313.639893]\n",
      "475 [D loss: -3543.069092] [G loss: -282.500793]\n",
      "476 [D loss: -3608.972900] [G loss: -305.136719]\n",
      "477 [D loss: -3509.659424] [G loss: -316.015930]\n",
      "478 [D loss: -3714.358154] [G loss: -273.401794]\n",
      "479 [D loss: -3513.678955] [G loss: -247.253754]\n",
      "480 [D loss: -3797.696289] [G loss: -284.635986]\n",
      "481 [D loss: -3786.698975] [G loss: -289.420441]\n",
      "482 [D loss: -3802.500732] [G loss: -339.706360]\n",
      "483 [D loss: -3638.050049] [G loss: -345.886658]\n",
      "484 [D loss: -3463.682861] [G loss: -292.040833]\n",
      "485 [D loss: -3792.741699] [G loss: -280.456177]\n",
      "486 [D loss: -3244.679688] [G loss: -271.240967]\n",
      "487 [D loss: -3825.241455] [G loss: -272.651123]\n",
      "488 [D loss: -3748.882812] [G loss: -257.804474]\n",
      "489 [D loss: -3795.501709] [G loss: -311.439026]\n",
      "490 [D loss: -3664.348389] [G loss: -342.130493]\n",
      "491 [D loss: -3905.220947] [G loss: -323.253540]\n",
      "492 [D loss: -3982.715576] [G loss: -345.301941]\n",
      "493 [D loss: -3900.395996] [G loss: -343.675446]\n",
      "494 [D loss: -3858.750244] [G loss: -298.160278]\n",
      "495 [D loss: -3819.630615] [G loss: -280.365875]\n",
      "496 [D loss: -3942.833496] [G loss: -315.762329]\n",
      "497 [D loss: -3501.995117] [G loss: -311.044312]\n",
      "498 [D loss: -4002.911621] [G loss: -298.419922]\n",
      "499 [D loss: -3943.848389] [G loss: -372.289551]\n",
      "500 [D loss: -3528.149902] [G loss: -321.664948]\n",
      "501 [D loss: -4005.145020] [G loss: -351.663452]\n",
      "502 [D loss: -3893.912842] [G loss: -293.140259]\n",
      "503 [D loss: -3847.982178] [G loss: -333.090607]\n",
      "504 [D loss: -3892.919189] [G loss: -358.026672]\n",
      "505 [D loss: -4079.340332] [G loss: -377.314331]\n",
      "506 [D loss: -4196.001465] [G loss: -320.400024]\n",
      "507 [D loss: -3902.922363] [G loss: -388.553802]\n",
      "508 [D loss: -3990.324463] [G loss: -340.734863]\n",
      "509 [D loss: -4013.004639] [G loss: -386.917145]\n",
      "510 [D loss: -4140.100586] [G loss: -354.791138]\n",
      "511 [D loss: -4083.903809] [G loss: -354.722046]\n",
      "512 [D loss: -4202.459473] [G loss: -357.886993]\n",
      "513 [D loss: -4051.169922] [G loss: -374.116730]\n",
      "514 [D loss: -4119.015625] [G loss: -356.163269]\n",
      "515 [D loss: -4262.327637] [G loss: -380.098694]\n",
      "516 [D loss: -4282.357422] [G loss: -311.049408]\n",
      "517 [D loss: -4252.598633] [G loss: -403.046356]\n",
      "518 [D loss: -4281.305664] [G loss: -386.235504]\n",
      "519 [D loss: -4274.588867] [G loss: -354.279572]\n",
      "520 [D loss: -4271.620605] [G loss: -335.833679]\n",
      "521 [D loss: -4170.011719] [G loss: -368.819885]\n",
      "522 [D loss: -4269.637207] [G loss: -380.502197]\n",
      "523 [D loss: -3930.466309] [G loss: -465.562805]\n",
      "524 [D loss: -4328.344727] [G loss: -400.788147]\n",
      "525 [D loss: -4371.048828] [G loss: -348.174805]\n",
      "526 [D loss: -4415.937988] [G loss: -395.937195]\n",
      "527 [D loss: -4296.875000] [G loss: -489.505615]\n",
      "528 [D loss: -4428.373047] [G loss: -422.574890]\n",
      "529 [D loss: -4465.995117] [G loss: -382.665619]\n",
      "530 [D loss: -4412.113281] [G loss: -416.864777]\n",
      "531 [D loss: -4459.627930] [G loss: -399.263550]\n",
      "532 [D loss: -4455.831543] [G loss: -411.195801]\n",
      "533 [D loss: -4496.036621] [G loss: -397.294220]\n",
      "534 [D loss: -4465.827148] [G loss: -353.842468]\n",
      "535 [D loss: -4488.977539] [G loss: -417.031403]\n",
      "536 [D loss: -4449.007324] [G loss: -402.183411]\n",
      "537 [D loss: -4530.304688] [G loss: -430.259644]\n",
      "538 [D loss: -4551.102051] [G loss: -457.297852]\n",
      "539 [D loss: -4526.142090] [G loss: -448.786804]\n",
      "540 [D loss: -4609.111328] [G loss: -451.469543]\n",
      "541 [D loss: -4508.441406] [G loss: -457.753876]\n",
      "542 [D loss: -4591.618164] [G loss: -491.218811]\n",
      "543 [D loss: -4545.187500] [G loss: -489.858459]\n",
      "544 [D loss: -4424.923828] [G loss: -449.718323]\n",
      "545 [D loss: -4625.961426] [G loss: -443.556793]\n",
      "546 [D loss: -4684.944336] [G loss: -418.092346]\n",
      "547 [D loss: -4696.396484] [G loss: -498.147736]\n",
      "548 [D loss: -4679.466797] [G loss: -539.590210]\n",
      "549 [D loss: -4594.336914] [G loss: -440.561523]\n",
      "550 [D loss: -4657.280762] [G loss: -409.604370]\n",
      "551 [D loss: -4489.881836] [G loss: -455.548279]\n",
      "552 [D loss: -4718.732910] [G loss: -451.067413]\n",
      "553 [D loss: -4783.732422] [G loss: -429.580719]\n",
      "554 [D loss: -4717.178223] [G loss: -476.953949]\n",
      "555 [D loss: -4798.243652] [G loss: -439.430298]\n",
      "556 [D loss: -4769.265625] [G loss: -484.420227]\n",
      "557 [D loss: -4790.043457] [G loss: -469.124878]\n",
      "558 [D loss: -4746.851074] [G loss: -385.461121]\n",
      "559 [D loss: -4806.105469] [G loss: -487.040070]\n",
      "560 [D loss: -4832.113281] [G loss: -516.373230]\n",
      "561 [D loss: -4826.501953] [G loss: -480.364075]\n",
      "562 [D loss: -4771.841797] [G loss: -486.108337]\n",
      "563 [D loss: -4876.830078] [G loss: -462.548462]\n",
      "564 [D loss: -4901.134766] [G loss: -416.942932]\n",
      "565 [D loss: -4791.400391] [G loss: -463.411102]\n",
      "566 [D loss: -4891.855957] [G loss: -503.749481]\n",
      "567 [D loss: -4800.451172] [G loss: -459.947083]\n",
      "568 [D loss: -4871.853027] [G loss: -449.333832]\n",
      "569 [D loss: -4775.576172] [G loss: -468.988892]\n",
      "570 [D loss: -4878.150391] [G loss: -467.054016]\n",
      "571 [D loss: -5004.632324] [G loss: -504.637177]\n",
      "572 [D loss: -5015.684082] [G loss: -519.895996]\n",
      "573 [D loss: -4999.603516] [G loss: -538.439331]\n",
      "574 [D loss: -4989.122070] [G loss: -472.299622]\n",
      "575 [D loss: -4972.784668] [G loss: -503.931641]\n",
      "576 [D loss: -5074.674316] [G loss: -475.399872]\n",
      "577 [D loss: -5052.793457] [G loss: -525.860474]\n",
      "578 [D loss: -5078.093750] [G loss: -544.000122]\n",
      "579 [D loss: -5035.166504] [G loss: -518.250488]\n",
      "580 [D loss: -5151.940430] [G loss: -459.689758]\n",
      "581 [D loss: -5071.099121] [G loss: -500.454163]\n",
      "582 [D loss: -5088.635742] [G loss: -523.015259]\n",
      "583 [D loss: -5162.636230] [G loss: -520.267822]\n",
      "584 [D loss: -5145.120605] [G loss: -562.563477]\n",
      "585 [D loss: -5197.528809] [G loss: -517.379028]\n",
      "586 [D loss: -5225.985352] [G loss: -581.953430]\n",
      "587 [D loss: -5208.410645] [G loss: -562.055176]\n",
      "588 [D loss: -5254.373047] [G loss: -576.771729]\n",
      "589 [D loss: -5233.031250] [G loss: -601.286011]\n",
      "590 [D loss: -5177.615234] [G loss: -542.332703]\n",
      "591 [D loss: -5260.638184] [G loss: -550.674438]\n",
      "592 [D loss: -5254.378906] [G loss: -545.395752]\n",
      "593 [D loss: -5254.982422] [G loss: -590.019897]\n",
      "594 [D loss: -5293.907227] [G loss: -552.355835]\n",
      "595 [D loss: -5315.377930] [G loss: -528.098267]\n",
      "596 [D loss: -5285.314453] [G loss: -510.096252]\n",
      "597 [D loss: -5238.134277] [G loss: -572.108765]\n",
      "598 [D loss: -5315.070801] [G loss: -571.878540]\n",
      "599 [D loss: -5393.830078] [G loss: -589.855286]\n",
      "600 [D loss: -5354.444824] [G loss: -514.209290]\n",
      "601 [D loss: -5358.463867] [G loss: -508.000305]\n",
      "602 [D loss: -5426.200195] [G loss: -585.725220]\n",
      "603 [D loss: -5401.880371] [G loss: -504.680237]\n",
      "604 [D loss: -5457.282715] [G loss: -517.645325]\n",
      "605 [D loss: -5408.585449] [G loss: -563.730835]\n",
      "606 [D loss: -5449.138184] [G loss: -574.306885]\n",
      "607 [D loss: -5463.481934] [G loss: -598.404175]\n",
      "608 [D loss: -5427.687500] [G loss: -586.585815]\n",
      "609 [D loss: -5464.450195] [G loss: -544.314880]\n",
      "610 [D loss: -5455.272461] [G loss: -549.522644]\n",
      "611 [D loss: -5461.185059] [G loss: -613.141357]\n",
      "612 [D loss: -5523.933594] [G loss: -620.348145]\n",
      "613 [D loss: -5509.794922] [G loss: -580.309204]\n",
      "614 [D loss: -5563.871582] [G loss: -629.765869]\n",
      "615 [D loss: -5533.397949] [G loss: -683.163269]\n",
      "616 [D loss: -5517.977051] [G loss: -641.339478]\n",
      "617 [D loss: -5626.806152] [G loss: -580.902283]\n",
      "618 [D loss: -5637.215820] [G loss: -628.719666]\n",
      "619 [D loss: -5634.531738] [G loss: -605.380371]\n",
      "620 [D loss: -5637.679688] [G loss: -626.278809]\n",
      "621 [D loss: -5616.702637] [G loss: -664.521667]\n",
      "622 [D loss: -5667.551758] [G loss: -661.666443]\n",
      "623 [D loss: -5692.979004] [G loss: -649.692383]\n",
      "624 [D loss: -5700.398926] [G loss: -621.734558]\n",
      "625 [D loss: -5753.407715] [G loss: -599.301208]\n",
      "626 [D loss: -5744.115234] [G loss: -650.172546]\n",
      "627 [D loss: -5730.174805] [G loss: -568.297363]\n",
      "628 [D loss: -5754.740234] [G loss: -599.094666]\n",
      "629 [D loss: -5776.321777] [G loss: -603.699524]\n",
      "630 [D loss: -5731.689453] [G loss: -639.022034]\n",
      "631 [D loss: -5816.542969] [G loss: -615.032593]\n",
      "632 [D loss: -5833.087891] [G loss: -618.077698]\n",
      "633 [D loss: -5814.016602] [G loss: -664.019897]\n",
      "634 [D loss: -5901.229004] [G loss: -604.948547]\n",
      "635 [D loss: -5826.293457] [G loss: -638.120728]\n",
      "636 [D loss: -5870.435059] [G loss: -685.738525]\n",
      "637 [D loss: -5885.096191] [G loss: -665.874634]\n",
      "638 [D loss: -5816.257812] [G loss: -694.758362]\n",
      "639 [D loss: -5931.339844] [G loss: -612.423340]\n",
      "640 [D loss: -5727.077148] [G loss: -678.025391]\n",
      "641 [D loss: -5930.737305] [G loss: -645.205688]\n",
      "642 [D loss: -5891.483887] [G loss: -717.722595]\n",
      "643 [D loss: -5969.826660] [G loss: -659.284302]\n",
      "644 [D loss: -5991.728516] [G loss: -629.496460]\n",
      "645 [D loss: -5977.836914] [G loss: -684.134399]\n",
      "646 [D loss: -5983.777832] [G loss: -655.425903]\n",
      "647 [D loss: -6070.235840] [G loss: -674.720093]\n",
      "648 [D loss: -6051.051270] [G loss: -696.482178]\n",
      "649 [D loss: -6050.212891] [G loss: -636.395081]\n",
      "650 [D loss: -6089.066895] [G loss: -686.307617]\n",
      "651 [D loss: -6059.060059] [G loss: -624.009888]\n",
      "652 [D loss: -6090.043945] [G loss: -647.832520]\n",
      "653 [D loss: -6061.151367] [G loss: -713.404541]\n",
      "654 [D loss: -6141.024902] [G loss: -647.679810]\n",
      "655 [D loss: -6108.530762] [G loss: -668.936340]\n",
      "656 [D loss: -6044.015625] [G loss: -806.150391]\n",
      "657 [D loss: -6160.750000] [G loss: -682.296143]\n",
      "658 [D loss: -6146.911621] [G loss: -678.347412]\n",
      "659 [D loss: -6219.750488] [G loss: -696.588684]\n",
      "660 [D loss: -6186.788574] [G loss: -662.927856]\n",
      "661 [D loss: -6212.452148] [G loss: -753.663391]\n",
      "662 [D loss: -6206.222656] [G loss: -778.696899]\n",
      "663 [D loss: -6274.021484] [G loss: -712.376221]\n",
      "664 [D loss: -6215.000000] [G loss: -779.655151]\n",
      "665 [D loss: -6280.978027] [G loss: -691.078613]\n",
      "666 [D loss: -6312.247559] [G loss: -642.872314]\n",
      "667 [D loss: -6284.597656] [G loss: -699.906860]\n",
      "668 [D loss: -6307.989258] [G loss: -699.776184]\n",
      "669 [D loss: -6331.781250] [G loss: -731.267273]\n",
      "670 [D loss: -6292.549316] [G loss: -763.302551]\n",
      "671 [D loss: -6367.434570] [G loss: -766.303345]\n",
      "672 [D loss: -6395.156250] [G loss: -758.199219]\n",
      "673 [D loss: -6428.341797] [G loss: -820.247620]\n",
      "674 [D loss: -6380.549805] [G loss: -718.481445]\n",
      "675 [D loss: -6420.534668] [G loss: -798.612793]\n",
      "676 [D loss: -6393.173828] [G loss: -725.199951]\n",
      "677 [D loss: -6440.103516] [G loss: -798.681091]\n",
      "678 [D loss: -6500.638184] [G loss: -729.101868]\n",
      "679 [D loss: -6519.605957] [G loss: -739.349915]\n",
      "680 [D loss: -6483.068848] [G loss: -705.776184]\n",
      "681 [D loss: -6508.952637] [G loss: -891.721558]\n",
      "682 [D loss: -6498.244629] [G loss: -704.501404]\n",
      "683 [D loss: -6539.864746] [G loss: -714.905457]\n",
      "684 [D loss: -6564.309570] [G loss: -874.349243]\n",
      "685 [D loss: -6568.246094] [G loss: -773.684631]\n",
      "686 [D loss: -6586.560547] [G loss: -811.271179]\n",
      "687 [D loss: -6623.583984] [G loss: -835.474548]\n",
      "688 [D loss: -6644.692871] [G loss: -783.129517]\n",
      "689 [D loss: -6655.223145] [G loss: -680.767944]\n",
      "690 [D loss: -6539.078125] [G loss: -874.939087]\n",
      "691 [D loss: -6647.402344] [G loss: -838.504761]\n",
      "692 [D loss: -6672.836426] [G loss: -849.026855]\n",
      "693 [D loss: -6686.552734] [G loss: -748.375061]\n",
      "694 [D loss: -6737.712402] [G loss: -844.502258]\n",
      "695 [D loss: -6741.557129] [G loss: -760.962402]\n",
      "696 [D loss: -6726.665527] [G loss: -864.577881]\n",
      "697 [D loss: -6763.633789] [G loss: -766.024292]\n",
      "698 [D loss: -6709.434082] [G loss: -785.106934]\n",
      "699 [D loss: -6781.256836] [G loss: -729.188965]\n",
      "700 [D loss: -6797.500488] [G loss: -813.510498]\n",
      "701 [D loss: -6722.246582] [G loss: -860.251709]\n",
      "702 [D loss: -6791.339844] [G loss: -929.845459]\n",
      "703 [D loss: -6801.399902] [G loss: -816.057190]\n",
      "704 [D loss: -6824.574707] [G loss: -820.487671]\n",
      "705 [D loss: -6830.896973] [G loss: -832.179932]\n",
      "706 [D loss: -6822.958496] [G loss: -845.043823]\n",
      "707 [D loss: -6913.755859] [G loss: -860.032288]\n",
      "708 [D loss: -6901.742188] [G loss: -943.692749]\n",
      "709 [D loss: -6887.912109] [G loss: -916.736145]\n",
      "710 [D loss: -6845.031738] [G loss: -905.858154]\n",
      "711 [D loss: -6965.931152] [G loss: -898.797241]\n",
      "712 [D loss: -6981.287109] [G loss: -865.557495]\n",
      "713 [D loss: -6947.482422] [G loss: -795.815308]\n",
      "714 [D loss: -6941.250488] [G loss: -832.248169]\n",
      "715 [D loss: -7009.582520] [G loss: -884.066406]\n",
      "716 [D loss: -7036.438477] [G loss: -992.444946]\n",
      "717 [D loss: -7034.442871] [G loss: -880.767151]\n",
      "718 [D loss: -7039.921875] [G loss: -908.142090]\n",
      "719 [D loss: -7083.168457] [G loss: -856.546875]\n",
      "720 [D loss: -7070.100586] [G loss: -904.787354]\n",
      "721 [D loss: -7098.029785] [G loss: -821.678589]\n",
      "722 [D loss: -7118.466797] [G loss: -889.566895]\n",
      "723 [D loss: -7129.934570] [G loss: -860.821960]\n",
      "724 [D loss: -7141.346191] [G loss: -888.227600]\n",
      "725 [D loss: -7127.378418] [G loss: -943.686462]\n",
      "726 [D loss: -7143.953613] [G loss: -946.925232]\n",
      "727 [D loss: -7202.882324] [G loss: -881.899170]\n",
      "728 [D loss: -7179.363281] [G loss: -1017.511108]\n",
      "729 [D loss: -7237.709961] [G loss: -871.358521]\n",
      "730 [D loss: -7234.096191] [G loss: -894.300476]\n",
      "731 [D loss: -7213.227539] [G loss: -1004.150757]\n",
      "732 [D loss: -7264.977051] [G loss: -930.564148]\n",
      "733 [D loss: -7269.519531] [G loss: -894.453064]\n",
      "734 [D loss: -7234.277344] [G loss: -921.603882]\n",
      "735 [D loss: -7302.157227] [G loss: -867.687744]\n",
      "736 [D loss: -7276.983887] [G loss: -1001.132202]\n",
      "737 [D loss: -7317.477051] [G loss: -856.521057]\n",
      "738 [D loss: -7343.448730] [G loss: -940.992493]\n",
      "739 [D loss: -7316.852539] [G loss: -977.578308]\n",
      "740 [D loss: -7365.335938] [G loss: -979.720947]\n",
      "741 [D loss: -7374.776367] [G loss: -860.830994]\n",
      "742 [D loss: -7395.126465] [G loss: -1005.028015]\n",
      "743 [D loss: -7375.404297] [G loss: -1054.314209]\n",
      "744 [D loss: -7418.129395] [G loss: -1001.627808]\n",
      "745 [D loss: -7390.761230] [G loss: -948.170532]\n",
      "746 [D loss: -7424.534180] [G loss: -896.851562]\n",
      "747 [D loss: -7482.887207] [G loss: -884.279419]\n",
      "748 [D loss: -7461.887695] [G loss: -914.257080]\n",
      "749 [D loss: -7465.279785] [G loss: -920.488525]\n",
      "750 [D loss: -7498.709473] [G loss: -927.756226]\n",
      "751 [D loss: -7523.447266] [G loss: -1050.603027]\n",
      "752 [D loss: -7529.137207] [G loss: -1006.143066]\n",
      "753 [D loss: -7537.806641] [G loss: -940.818054]\n",
      "754 [D loss: -7571.391602] [G loss: -979.516785]\n",
      "755 [D loss: -7603.242676] [G loss: -868.164856]\n",
      "756 [D loss: -7596.057129] [G loss: -1022.598389]\n",
      "757 [D loss: -7570.662109] [G loss: -1024.399414]\n",
      "758 [D loss: -7635.875488] [G loss: -1021.284851]\n",
      "759 [D loss: -7581.254395] [G loss: -1074.269775]\n",
      "760 [D loss: -7635.137695] [G loss: -957.220398]\n",
      "761 [D loss: -7659.389648] [G loss: -937.511597]\n",
      "762 [D loss: -7710.637695] [G loss: -961.299316]\n",
      "763 [D loss: -7713.081055] [G loss: -1006.980652]\n",
      "764 [D loss: -7769.028809] [G loss: -913.344604]\n",
      "765 [D loss: -7746.857910] [G loss: -966.886353]\n",
      "766 [D loss: -7760.792480] [G loss: -1021.325928]\n",
      "767 [D loss: -7728.779297] [G loss: -1085.350220]\n",
      "768 [D loss: -7722.180664] [G loss: -1112.721069]\n",
      "769 [D loss: -7794.342285] [G loss: -1118.143555]\n",
      "770 [D loss: -7830.051758] [G loss: -983.710144]\n",
      "771 [D loss: -7783.461426] [G loss: -1151.424072]\n",
      "772 [D loss: -7875.006348] [G loss: -1060.889160]\n",
      "773 [D loss: -7748.195801] [G loss: -988.615112]\n",
      "774 [D loss: -7849.419922] [G loss: -1150.205322]\n",
      "775 [D loss: -7875.840820] [G loss: -1095.357422]\n",
      "776 [D loss: -7843.984375] [G loss: -1114.382080]\n",
      "777 [D loss: -7916.894043] [G loss: -1070.823730]\n",
      "778 [D loss: -7887.663086] [G loss: -1123.914062]\n",
      "779 [D loss: -7919.776367] [G loss: -1172.545166]\n",
      "780 [D loss: -7920.593262] [G loss: -1099.977539]\n",
      "781 [D loss: -7956.775391] [G loss: -1131.673096]\n",
      "782 [D loss: -7997.453125] [G loss: -1111.887695]\n",
      "783 [D loss: -7974.674316] [G loss: -1030.670898]\n",
      "784 [D loss: -8010.545410] [G loss: -1065.395142]\n",
      "785 [D loss: -8016.266113] [G loss: -1170.608154]\n",
      "786 [D loss: -8044.034668] [G loss: -1113.674438]\n",
      "787 [D loss: -8063.944824] [G loss: -1036.445190]\n",
      "788 [D loss: -8080.125000] [G loss: -1145.340820]\n",
      "789 [D loss: -8046.045898] [G loss: -1192.201660]\n",
      "790 [D loss: -8114.945312] [G loss: -1145.831299]\n",
      "791 [D loss: -8110.835938] [G loss: -1148.161865]\n",
      "792 [D loss: -8167.937012] [G loss: -1074.871582]\n",
      "793 [D loss: -8161.770996] [G loss: -1057.972900]\n",
      "794 [D loss: -8130.018555] [G loss: -1112.161255]\n",
      "795 [D loss: -8100.450195] [G loss: -1300.207275]\n",
      "796 [D loss: -8237.096680] [G loss: -1162.751343]\n",
      "797 [D loss: -8161.061523] [G loss: -1125.680542]\n",
      "798 [D loss: -8197.443359] [G loss: -1209.793701]\n",
      "799 [D loss: -8235.906250] [G loss: -1163.487305]\n",
      "800 [D loss: -8277.178711] [G loss: -1076.331787]\n",
      "801 [D loss: -8286.671875] [G loss: -1179.301270]\n",
      "802 [D loss: -8290.952148] [G loss: -1298.186523]\n",
      "803 [D loss: -8262.071289] [G loss: -1253.069092]\n",
      "804 [D loss: -8325.282227] [G loss: -1167.548462]\n",
      "805 [D loss: -8374.521484] [G loss: -1181.878540]\n",
      "806 [D loss: -8332.166016] [G loss: -1206.440308]\n",
      "807 [D loss: -8374.050781] [G loss: -1320.198730]\n",
      "808 [D loss: -8390.447266] [G loss: -1131.118164]\n",
      "809 [D loss: -8404.424805] [G loss: -1082.764893]\n",
      "810 [D loss: -8410.069336] [G loss: -1095.124268]\n",
      "811 [D loss: -8389.789062] [G loss: -1242.028687]\n",
      "812 [D loss: -8367.582031] [G loss: -1109.354004]\n",
      "813 [D loss: -8474.681641] [G loss: -1220.472168]\n",
      "814 [D loss: -8477.295898] [G loss: -1108.869629]\n",
      "815 [D loss: -8443.541016] [G loss: -1215.503662]\n",
      "816 [D loss: -8515.556641] [G loss: -1215.399292]\n",
      "817 [D loss: -8549.147461] [G loss: -1276.443604]\n",
      "818 [D loss: -8527.388672] [G loss: -1269.465820]\n",
      "819 [D loss: -8546.654297] [G loss: -1228.198608]\n",
      "820 [D loss: -8503.405273] [G loss: -1179.764404]\n",
      "821 [D loss: -8567.611328] [G loss: -1194.992432]\n",
      "822 [D loss: -8628.563477] [G loss: -1262.692383]\n",
      "823 [D loss: -8632.596680] [G loss: -1237.225098]\n",
      "824 [D loss: -8650.235352] [G loss: -1267.686523]\n",
      "825 [D loss: -8675.983398] [G loss: -1169.264038]\n",
      "826 [D loss: -8623.077148] [G loss: -1312.898315]\n",
      "827 [D loss: -8642.167969] [G loss: -1229.116821]\n",
      "828 [D loss: -8639.190430] [G loss: -1226.911621]\n",
      "829 [D loss: -8698.041992] [G loss: -1082.087402]\n",
      "830 [D loss: -8743.268555] [G loss: -1303.466553]\n",
      "831 [D loss: -8763.402344] [G loss: -1315.166016]\n",
      "832 [D loss: -8749.746094] [G loss: -1184.907471]\n",
      "833 [D loss: -8792.196289] [G loss: -1081.258301]\n",
      "834 [D loss: -8776.823242] [G loss: -1354.638428]\n",
      "835 [D loss: -8774.310547] [G loss: -1220.089600]\n",
      "836 [D loss: -8817.648438] [G loss: -1167.086670]\n",
      "837 [D loss: -8856.513672] [G loss: -1245.627197]\n",
      "838 [D loss: -8850.700195] [G loss: -1310.866699]\n",
      "839 [D loss: -8849.780273] [G loss: -1399.064697]\n",
      "840 [D loss: -8910.735352] [G loss: -1228.789795]\n",
      "841 [D loss: -8837.849609] [G loss: -1303.997559]\n",
      "842 [D loss: -8898.587891] [G loss: -1341.811279]\n",
      "843 [D loss: -8940.927734] [G loss: -1351.856934]\n",
      "844 [D loss: -8937.600586] [G loss: -1239.106934]\n",
      "845 [D loss: -8972.184570] [G loss: -1213.621216]\n",
      "846 [D loss: -8976.841797] [G loss: -1249.275391]\n",
      "847 [D loss: -9032.507812] [G loss: -1430.768188]\n",
      "848 [D loss: -8989.800781] [G loss: -1327.076172]\n",
      "849 [D loss: -9003.704102] [G loss: -1301.697876]\n",
      "850 [D loss: -9004.074219] [G loss: -1335.693359]\n",
      "851 [D loss: -9025.920898] [G loss: -1408.051514]\n",
      "852 [D loss: -9029.341797] [G loss: -1213.092529]\n",
      "853 [D loss: -9068.800781] [G loss: -1337.463135]\n",
      "854 [D loss: -9080.465820] [G loss: -1331.289062]\n",
      "855 [D loss: -9132.177734] [G loss: -1200.730225]\n",
      "856 [D loss: -9166.884766] [G loss: -1328.336914]\n",
      "857 [D loss: -9128.039062] [G loss: -1237.216309]\n",
      "858 [D loss: -9176.514648] [G loss: -1271.351196]\n",
      "859 [D loss: -9196.847656] [G loss: -1309.688965]\n",
      "860 [D loss: -9139.864258] [G loss: -1305.895264]\n",
      "861 [D loss: -9244.303711] [G loss: -1372.479736]\n",
      "862 [D loss: -9222.986328] [G loss: -1361.438232]\n",
      "863 [D loss: -9240.948242] [G loss: -1388.204834]\n",
      "864 [D loss: -9279.879883] [G loss: -1238.457397]\n",
      "865 [D loss: -9227.389648] [G loss: -1349.790161]\n",
      "866 [D loss: -9269.459961] [G loss: -1405.935303]\n",
      "867 [D loss: -9323.241211] [G loss: -1314.374023]\n",
      "868 [D loss: -9323.928711] [G loss: -1487.221436]\n",
      "869 [D loss: -9319.830078] [G loss: -1463.263916]\n",
      "870 [D loss: -9377.599609] [G loss: -1343.082275]\n",
      "871 [D loss: -9394.089844] [G loss: -1462.313232]\n",
      "872 [D loss: -9363.555664] [G loss: -1462.789185]\n",
      "873 [D loss: -9383.517578] [G loss: -1419.531738]\n",
      "874 [D loss: -9260.875977] [G loss: -1305.633057]\n",
      "875 [D loss: -9458.462891] [G loss: -1428.812866]\n",
      "876 [D loss: -9505.259766] [G loss: -1397.890381]\n",
      "877 [D loss: -9467.738281] [G loss: -1406.967773]\n",
      "878 [D loss: -9419.499023] [G loss: -1594.177734]\n",
      "879 [D loss: -9521.430664] [G loss: -1337.430420]\n",
      "880 [D loss: -9578.664062] [G loss: -1421.469971]\n",
      "881 [D loss: -9510.288086] [G loss: -1331.382568]\n",
      "882 [D loss: -9549.258789] [G loss: -1314.041748]\n",
      "883 [D loss: -9510.552734] [G loss: -1380.511963]\n",
      "884 [D loss: -9541.341797] [G loss: -1336.525879]\n",
      "885 [D loss: -9544.543945] [G loss: -1666.143555]\n",
      "886 [D loss: -9561.761719] [G loss: -1411.187988]\n",
      "887 [D loss: -9653.770508] [G loss: -1396.689209]\n",
      "888 [D loss: -9636.845703] [G loss: -1623.279785]\n",
      "889 [D loss: -9625.856445] [G loss: -1521.119507]\n",
      "890 [D loss: -9655.483398] [G loss: -1445.962891]\n",
      "891 [D loss: -9655.830078] [G loss: -1543.468506]\n",
      "892 [D loss: -9787.972656] [G loss: -1479.101929]\n",
      "893 [D loss: -9703.164062] [G loss: -1409.317139]\n",
      "894 [D loss: -9720.824219] [G loss: -1583.016113]\n",
      "895 [D loss: -9772.216797] [G loss: -1482.604248]\n",
      "896 [D loss: -9787.268555] [G loss: -1456.033447]\n",
      "897 [D loss: -9771.797852] [G loss: -1528.004639]\n",
      "898 [D loss: -9843.023438] [G loss: -1483.465088]\n",
      "899 [D loss: -9879.975586] [G loss: -1487.541748]\n",
      "900 [D loss: -9849.782227] [G loss: -1474.127319]\n",
      "901 [D loss: -9871.693359] [G loss: -1452.423950]\n",
      "902 [D loss: -9858.366211] [G loss: -1506.822021]\n",
      "903 [D loss: -9943.659180] [G loss: -1571.868408]\n",
      "904 [D loss: -9885.735352] [G loss: -1490.342773]\n",
      "905 [D loss: -9976.181641] [G loss: -1486.988770]\n",
      "906 [D loss: -9893.329102] [G loss: -1502.333252]\n",
      "907 [D loss: -9961.290039] [G loss: -1586.927002]\n",
      "908 [D loss: -9880.463867] [G loss: -1527.244141]\n",
      "909 [D loss: -10021.434570] [G loss: -1497.078735]\n",
      "910 [D loss: -9995.705078] [G loss: -1584.800293]\n",
      "911 [D loss: -10051.000977] [G loss: -1486.101074]\n",
      "912 [D loss: -10068.322266] [G loss: -1504.226929]\n",
      "913 [D loss: -10010.405273] [G loss: -1564.614746]\n",
      "914 [D loss: -10100.391602] [G loss: -1550.231445]\n",
      "915 [D loss: -10093.575195] [G loss: -1518.687744]\n",
      "916 [D loss: -10028.416016] [G loss: -1525.452637]\n",
      "917 [D loss: -10142.720703] [G loss: -1515.855713]\n",
      "918 [D loss: -10125.007812] [G loss: -1492.110474]\n",
      "919 [D loss: -10128.352539] [G loss: -1756.821899]\n",
      "920 [D loss: -10175.063477] [G loss: -1672.830811]\n",
      "921 [D loss: -10176.859375] [G loss: -1516.114014]\n",
      "922 [D loss: -10183.145508] [G loss: -1489.483643]\n",
      "923 [D loss: -10259.111328] [G loss: -1613.252930]\n",
      "924 [D loss: -10280.284180] [G loss: -1472.391357]\n",
      "925 [D loss: -10254.212891] [G loss: -1642.926025]\n",
      "926 [D loss: -10291.315430] [G loss: -1588.949463]\n",
      "927 [D loss: -10348.181641] [G loss: -1526.418213]\n",
      "928 [D loss: -10266.497070] [G loss: -1625.030762]\n",
      "929 [D loss: -10351.693359] [G loss: -1545.688721]\n",
      "930 [D loss: -10353.429688] [G loss: -1702.628418]\n",
      "931 [D loss: -10330.495117] [G loss: -1650.468994]\n",
      "932 [D loss: -10378.079102] [G loss: -1676.453125]\n",
      "933 [D loss: -10401.608398] [G loss: -1719.374023]\n",
      "934 [D loss: -10432.265625] [G loss: -1661.000122]\n",
      "935 [D loss: -10450.761719] [G loss: -1651.779297]\n",
      "936 [D loss: -10467.365234] [G loss: -1719.917969]\n",
      "937 [D loss: -10472.142578] [G loss: -1692.390869]\n",
      "938 [D loss: -10474.081055] [G loss: -1765.697510]\n",
      "939 [D loss: -10520.400391] [G loss: -1762.373535]\n",
      "940 [D loss: -10527.201172] [G loss: -1719.659180]\n",
      "941 [D loss: -10551.136719] [G loss: -1729.922241]\n",
      "942 [D loss: -10517.058594] [G loss: -1478.970337]\n",
      "943 [D loss: -10612.977539] [G loss: -1686.947754]\n",
      "944 [D loss: -10625.105469] [G loss: -1621.143066]\n",
      "945 [D loss: -10639.061523] [G loss: -1776.095459]\n",
      "946 [D loss: -10647.239258] [G loss: -1605.983765]\n",
      "947 [D loss: -10579.532227] [G loss: -1695.166748]\n",
      "948 [D loss: -10609.250977] [G loss: -1591.718750]\n",
      "949 [D loss: -10668.777344] [G loss: -1767.734253]\n",
      "950 [D loss: -10768.363281] [G loss: -1652.400513]\n",
      "951 [D loss: -10690.465820] [G loss: -1805.400146]\n",
      "952 [D loss: -10725.819336] [G loss: -1779.282227]\n",
      "953 [D loss: -10732.820312] [G loss: -1869.294678]\n",
      "954 [D loss: -10761.354492] [G loss: -1697.614136]\n",
      "955 [D loss: -10799.937500] [G loss: -1671.022217]\n",
      "956 [D loss: -10776.464844] [G loss: -1856.671387]\n",
      "957 [D loss: -10776.872070] [G loss: -1732.166504]\n",
      "958 [D loss: -10844.674805] [G loss: -1809.084595]\n",
      "959 [D loss: -10851.897461] [G loss: -1885.522095]\n",
      "960 [D loss: -10846.250000] [G loss: -1811.840820]\n",
      "961 [D loss: -10860.308594] [G loss: -1696.922363]\n",
      "962 [D loss: -10943.843750] [G loss: -1701.158936]\n",
      "963 [D loss: -10913.754883] [G loss: -1845.396118]\n",
      "964 [D loss: -10962.053711] [G loss: -1899.118530]\n",
      "965 [D loss: -10886.200195] [G loss: -1947.316162]\n",
      "966 [D loss: -10958.739258] [G loss: -1673.193848]\n",
      "967 [D loss: -10953.046875] [G loss: -1954.226685]\n",
      "968 [D loss: -10971.132812] [G loss: -2004.826294]\n",
      "969 [D loss: -11012.239258] [G loss: -1655.321289]\n",
      "970 [D loss: -10999.670898] [G loss: -1817.838623]\n",
      "971 [D loss: -10811.068359] [G loss: -1899.145996]\n",
      "972 [D loss: -11025.161133] [G loss: -1829.863281]\n",
      "973 [D loss: -11092.181641] [G loss: -1887.277710]\n",
      "974 [D loss: -11095.061523] [G loss: -1653.895630]\n",
      "975 [D loss: -11123.268555] [G loss: -1917.394409]\n",
      "976 [D loss: -11158.792969] [G loss: -1680.953125]\n",
      "977 [D loss: -11154.159180] [G loss: -1752.740723]\n",
      "978 [D loss: -11171.618164] [G loss: -1789.063843]\n",
      "979 [D loss: -11168.682617] [G loss: -1868.816895]\n",
      "980 [D loss: -11215.521484] [G loss: -1798.110107]\n",
      "981 [D loss: -11231.563477] [G loss: -1794.028809]\n",
      "982 [D loss: -11236.329102] [G loss: -1965.435059]\n",
      "983 [D loss: -11207.721680] [G loss: -1853.474854]\n",
      "984 [D loss: -11264.497070] [G loss: -1826.263672]\n",
      "985 [D loss: -11301.004883] [G loss: -1900.235352]\n",
      "986 [D loss: -11234.758789] [G loss: -1789.454834]\n",
      "987 [D loss: -11277.486328] [G loss: -1877.973389]\n",
      "988 [D loss: -11350.530273] [G loss: -1784.135498]\n",
      "989 [D loss: -11405.316406] [G loss: -1775.293457]\n",
      "990 [D loss: -11378.189453] [G loss: -1858.122559]\n",
      "991 [D loss: -11287.537109] [G loss: -1922.655762]\n",
      "992 [D loss: -11342.323242] [G loss: -1946.172607]\n",
      "993 [D loss: -11458.399414] [G loss: -1971.915039]\n",
      "994 [D loss: -11431.309570] [G loss: -1697.671021]\n",
      "995 [D loss: -11479.555664] [G loss: -2077.417480]\n",
      "996 [D loss: -11512.237305] [G loss: -1851.483643]\n",
      "997 [D loss: -11394.968750] [G loss: -2111.547363]\n",
      "998 [D loss: -11437.235352] [G loss: -1881.003174]\n",
      "999 [D loss: -11593.815430] [G loss: -2021.674805]\n",
      "1000 [D loss: -11513.177734] [G loss: -2086.810547]\n",
      "1001 [D loss: -11605.919922] [G loss: -1999.466919]\n",
      "1002 [D loss: -11581.378906] [G loss: -2053.421875]\n",
      "1003 [D loss: -11616.408203] [G loss: -1765.029663]\n",
      "1004 [D loss: -11597.407227] [G loss: -2106.240234]\n",
      "1005 [D loss: -11594.222656] [G loss: -2005.817627]\n",
      "1006 [D loss: -11657.397461] [G loss: -2131.975098]\n",
      "1007 [D loss: -11676.047852] [G loss: -1935.063721]\n",
      "1008 [D loss: -11634.781250] [G loss: -1850.908691]\n",
      "1009 [D loss: -11711.429688] [G loss: -1881.327515]\n",
      "1010 [D loss: -11708.673828] [G loss: -2043.352295]\n",
      "1011 [D loss: -11774.157227] [G loss: -1962.838257]\n",
      "1012 [D loss: -11704.169922] [G loss: -2149.775391]\n",
      "1013 [D loss: -11778.898438] [G loss: -2175.985596]\n",
      "1014 [D loss: -11816.923828] [G loss: -1851.639038]\n",
      "1015 [D loss: -11819.239258] [G loss: -1911.346436]\n",
      "1016 [D loss: -11766.049805] [G loss: -2047.604736]\n",
      "1017 [D loss: -11824.269531] [G loss: -1889.102783]\n",
      "1018 [D loss: -11793.565430] [G loss: -1928.468872]\n",
      "1019 [D loss: -11833.416992] [G loss: -2099.260742]\n",
      "1020 [D loss: -11877.269531] [G loss: -1952.042480]\n",
      "1021 [D loss: -11813.980469] [G loss: -1908.522705]\n",
      "1022 [D loss: -11974.603516] [G loss: -2016.023682]\n",
      "1023 [D loss: -11982.800781] [G loss: -1960.248291]\n",
      "1024 [D loss: -11994.078125] [G loss: -1924.915039]\n",
      "1025 [D loss: -11992.672852] [G loss: -1838.431396]\n",
      "1026 [D loss: -11970.423828] [G loss: -1985.691528]\n",
      "1027 [D loss: -12035.208984] [G loss: -2001.346924]\n",
      "1028 [D loss: -12049.761719] [G loss: -2079.287598]\n",
      "1029 [D loss: -12076.265625] [G loss: -1937.042725]\n",
      "1030 [D loss: -11986.810547] [G loss: -2167.131836]\n",
      "1031 [D loss: -12110.237305] [G loss: -2131.568848]\n",
      "1032 [D loss: -12157.917969] [G loss: -1735.625732]\n",
      "1033 [D loss: -12139.597656] [G loss: -1953.098389]\n",
      "1034 [D loss: -12125.546875] [G loss: -2111.482422]\n",
      "1035 [D loss: -12165.924805] [G loss: -2053.051514]\n",
      "1036 [D loss: -12197.594727] [G loss: -2026.781250]\n",
      "1037 [D loss: -12196.270508] [G loss: -2060.051514]\n",
      "1038 [D loss: -12218.112305] [G loss: -1929.789185]\n",
      "1039 [D loss: -12188.405273] [G loss: -2152.898438]\n",
      "1040 [D loss: -12235.082031] [G loss: -2074.323242]\n",
      "1041 [D loss: -12319.167969] [G loss: -2069.853516]\n",
      "1042 [D loss: -12269.991211] [G loss: -2001.938477]\n",
      "1043 [D loss: -12264.786133] [G loss: -2189.551758]\n",
      "1044 [D loss: -12338.754883] [G loss: -2051.324219]\n",
      "1045 [D loss: -12361.069336] [G loss: -2089.980225]\n",
      "1046 [D loss: -12360.370117] [G loss: -2227.231445]\n",
      "1047 [D loss: -12377.371094] [G loss: -2186.729980]\n",
      "1048 [D loss: -12346.256836] [G loss: -2448.966309]\n",
      "1049 [D loss: -12418.855469] [G loss: -2195.146973]\n",
      "1050 [D loss: -12373.814453] [G loss: -2080.971191]\n",
      "1051 [D loss: -12436.983398] [G loss: -2058.331543]\n",
      "1052 [D loss: -12374.928711] [G loss: -2148.855957]\n",
      "1053 [D loss: -12492.436523] [G loss: -2136.135254]\n",
      "1054 [D loss: -12549.759766] [G loss: -2190.087402]\n",
      "1055 [D loss: -12483.155273] [G loss: -2040.987549]\n",
      "1056 [D loss: -12539.072266] [G loss: -2062.552246]\n",
      "1057 [D loss: -12440.817383] [G loss: -2199.601807]\n",
      "1058 [D loss: -12544.202148] [G loss: -2182.758057]\n",
      "1059 [D loss: -12582.838867] [G loss: -2271.545410]\n",
      "1060 [D loss: -12586.416992] [G loss: -2309.360840]\n",
      "1061 [D loss: -12645.926758] [G loss: -2193.685547]\n",
      "1062 [D loss: -12604.400391] [G loss: -2436.002441]\n",
      "1063 [D loss: -12594.085938] [G loss: -2234.168213]\n",
      "1064 [D loss: -12671.081055] [G loss: -2231.763184]\n",
      "1065 [D loss: -12684.142578] [G loss: -2276.778564]\n",
      "1066 [D loss: -12660.172852] [G loss: -2255.146484]\n",
      "1067 [D loss: -12707.615234] [G loss: -2292.495605]\n",
      "1068 [D loss: -12690.134766] [G loss: -2448.375244]\n",
      "1069 [D loss: -12737.365234] [G loss: -2291.026123]\n",
      "1070 [D loss: -12719.759766] [G loss: -2431.370605]\n",
      "1071 [D loss: -12829.269531] [G loss: -2424.224609]\n",
      "1072 [D loss: -12759.719727] [G loss: -2385.241211]\n",
      "1073 [D loss: -12824.216797] [G loss: -2170.659912]\n",
      "1074 [D loss: -12851.464844] [G loss: -2338.047607]\n",
      "1075 [D loss: -12841.239258] [G loss: -2109.700684]\n",
      "1076 [D loss: -12854.694336] [G loss: -2161.305176]\n",
      "1077 [D loss: -12898.098633] [G loss: -2437.248535]\n",
      "1078 [D loss: -12912.027344] [G loss: -2255.918945]\n",
      "1079 [D loss: -12898.862305] [G loss: -2204.202148]\n",
      "1080 [D loss: -12902.545898] [G loss: -2147.104736]\n",
      "1081 [D loss: -12924.086914] [G loss: -2207.897949]\n",
      "1082 [D loss: -12983.946289] [G loss: -2243.737793]\n",
      "1083 [D loss: -12963.650391] [G loss: -2258.390381]\n",
      "1084 [D loss: -13007.110352] [G loss: -2535.431885]\n",
      "1085 [D loss: -13039.445312] [G loss: -2146.552490]\n",
      "1086 [D loss: -13056.746094] [G loss: -2285.183105]\n",
      "1087 [D loss: -12976.473633] [G loss: -2452.278564]\n",
      "1088 [D loss: -13074.721680] [G loss: -2365.946533]\n",
      "1089 [D loss: -13065.819336] [G loss: -2224.184082]\n",
      "1090 [D loss: -13153.048828] [G loss: -2338.067383]\n",
      "1091 [D loss: -13062.140625] [G loss: -2469.147461]\n",
      "1092 [D loss: -13141.111328] [G loss: -2383.337646]\n",
      "1093 [D loss: -13140.875977] [G loss: -2393.150879]\n",
      "1094 [D loss: -13245.806641] [G loss: -2158.561523]\n",
      "1095 [D loss: -13186.346680] [G loss: -2284.256348]\n",
      "1096 [D loss: -13208.888672] [G loss: -2399.065430]\n",
      "1097 [D loss: -13214.924805] [G loss: -2637.058105]\n",
      "1098 [D loss: -13261.422852] [G loss: -2193.968262]\n",
      "1099 [D loss: -13134.882812] [G loss: -2600.718262]\n",
      "1100 [D loss: -13270.724609] [G loss: -2412.699219]\n",
      "1101 [D loss: -13307.360352] [G loss: -2351.189941]\n",
      "1102 [D loss: -13263.496094] [G loss: -2460.907715]\n",
      "1103 [D loss: -13354.331055] [G loss: -2296.574707]\n",
      "1104 [D loss: -13405.541992] [G loss: -2414.873047]\n",
      "1105 [D loss: -13392.375000] [G loss: -2634.968262]\n",
      "1106 [D loss: -13305.295898] [G loss: -2323.294189]\n",
      "1107 [D loss: -13433.238281] [G loss: -2434.106445]\n",
      "1108 [D loss: -13371.095703] [G loss: -2300.666016]\n",
      "1109 [D loss: -13428.773438] [G loss: -2544.384521]\n",
      "1110 [D loss: -13437.972656] [G loss: -2446.439941]\n",
      "1111 [D loss: -13478.216797] [G loss: -2483.093994]\n",
      "1112 [D loss: -13443.712891] [G loss: -2482.255859]\n",
      "1113 [D loss: -13516.117188] [G loss: -2378.469238]\n",
      "1114 [D loss: -13424.150391] [G loss: -2420.769043]\n",
      "1115 [D loss: -13542.669922] [G loss: -2430.264893]\n",
      "1116 [D loss: -13536.199219] [G loss: -2523.732910]\n",
      "1117 [D loss: -13574.251953] [G loss: -2546.554688]\n",
      "1118 [D loss: -13515.204102] [G loss: -2615.693848]\n",
      "1119 [D loss: -13607.692383] [G loss: -2488.171631]\n",
      "1120 [D loss: -13657.359375] [G loss: -2516.895020]\n",
      "1121 [D loss: -13556.629883] [G loss: -2400.337646]\n",
      "1122 [D loss: -13694.220703] [G loss: -2606.285645]\n",
      "1123 [D loss: -13632.089844] [G loss: -2635.842285]\n",
      "1124 [D loss: -13711.188477] [G loss: -2630.550537]\n",
      "1125 [D loss: -13732.018555] [G loss: -2511.827637]\n",
      "1126 [D loss: -13726.368164] [G loss: -2486.470703]\n",
      "1127 [D loss: -13733.566406] [G loss: -2525.540771]\n",
      "1128 [D loss: -13807.358398] [G loss: -2650.630371]\n",
      "1129 [D loss: -13802.528320] [G loss: -2614.418213]\n",
      "1130 [D loss: -13800.658203] [G loss: -2542.288086]\n",
      "1131 [D loss: -13837.916992] [G loss: -2470.400879]\n",
      "1132 [D loss: -13814.899414] [G loss: -2521.653809]\n",
      "1133 [D loss: -13779.127930] [G loss: -2695.816895]\n",
      "1134 [D loss: -13816.511719] [G loss: -2689.353516]\n",
      "1135 [D loss: -13835.611328] [G loss: -2600.922852]\n",
      "1136 [D loss: -13887.267578] [G loss: -2494.583496]\n",
      "1137 [D loss: -13963.358398] [G loss: -2488.057129]\n",
      "1138 [D loss: -13908.028320] [G loss: -2536.873047]\n",
      "1139 [D loss: -13962.983398] [G loss: -2427.268066]\n",
      "1140 [D loss: -13984.748047] [G loss: -2601.262451]\n",
      "1141 [D loss: -13936.370117] [G loss: -2695.646973]\n",
      "1142 [D loss: -13995.458008] [G loss: -2932.778809]\n",
      "1143 [D loss: -13978.695312] [G loss: -2594.986816]\n",
      "1144 [D loss: -13972.746094] [G loss: -2606.874023]\n",
      "1145 [D loss: -14070.866211] [G loss: -2947.527832]\n",
      "1146 [D loss: -14012.992188] [G loss: -2426.855957]\n",
      "1147 [D loss: -14081.931641] [G loss: -2554.801758]\n",
      "1148 [D loss: -14152.495117] [G loss: -2496.833008]\n",
      "1149 [D loss: -14032.482422] [G loss: -2474.054688]\n",
      "1150 [D loss: -14118.787109] [G loss: -2673.626221]\n",
      "1151 [D loss: -14193.550781] [G loss: -2662.021973]\n",
      "1152 [D loss: -14241.088867] [G loss: -2741.296875]\n",
      "1153 [D loss: -14242.431641] [G loss: -2766.034180]\n",
      "1154 [D loss: -14250.493164] [G loss: -2797.600830]\n",
      "1155 [D loss: -14205.673828] [G loss: -2605.520752]\n",
      "1156 [D loss: -14222.346680] [G loss: -2533.668457]\n",
      "1157 [D loss: -14285.353516] [G loss: -2665.642578]\n",
      "1158 [D loss: -14187.004883] [G loss: -2532.747559]\n",
      "1159 [D loss: -14331.375000] [G loss: -2849.785400]\n",
      "1160 [D loss: -14253.887695] [G loss: -2856.162354]\n",
      "1161 [D loss: -14424.182617] [G loss: -2999.878174]\n",
      "1162 [D loss: -14410.513672] [G loss: -2664.172852]\n",
      "1163 [D loss: -14393.897461] [G loss: -2771.119873]\n",
      "1164 [D loss: -14429.084961] [G loss: -2653.210449]\n",
      "1165 [D loss: -14439.135742] [G loss: -2565.712891]\n",
      "1166 [D loss: -14449.688477] [G loss: -3105.186035]\n",
      "1167 [D loss: -14420.892578] [G loss: -2932.537842]\n",
      "1168 [D loss: -14538.019531] [G loss: -2859.245361]\n",
      "1169 [D loss: -14505.333984] [G loss: -2654.382324]\n",
      "1170 [D loss: -14556.161133] [G loss: -2846.080078]\n",
      "1171 [D loss: -14546.059570] [G loss: -2735.229980]\n",
      "1172 [D loss: -14559.401367] [G loss: -2916.763184]\n",
      "1173 [D loss: -14607.095703] [G loss: -2817.794434]\n",
      "1174 [D loss: -14571.543945] [G loss: -2778.602539]\n",
      "1175 [D loss: -14608.790039] [G loss: -2982.387207]\n",
      "1176 [D loss: -14603.881836] [G loss: -2984.757324]\n",
      "1177 [D loss: -14629.578125] [G loss: -2911.440918]\n",
      "1178 [D loss: -14695.302734] [G loss: -2878.044922]\n",
      "1179 [D loss: -14672.872070] [G loss: -3017.657227]\n",
      "1180 [D loss: -14702.521484] [G loss: -3065.965332]\n",
      "1181 [D loss: -14670.769531] [G loss: -2773.449707]\n",
      "1182 [D loss: -14741.404297] [G loss: -2869.647949]\n",
      "1183 [D loss: -14798.929688] [G loss: -2953.220215]\n",
      "1184 [D loss: -14829.173828] [G loss: -3066.733887]\n",
      "1185 [D loss: -14814.277344] [G loss: -2854.329590]\n",
      "1186 [D loss: -14812.421875] [G loss: -2866.541016]\n",
      "1187 [D loss: -14849.844727] [G loss: -2819.711426]\n",
      "1188 [D loss: -14931.257812] [G loss: -3130.239746]\n",
      "1189 [D loss: -14903.735352] [G loss: -2941.542236]\n",
      "1190 [D loss: -14872.811523] [G loss: -2859.049316]\n",
      "1191 [D loss: -14927.042969] [G loss: -2748.032471]\n",
      "1192 [D loss: -14956.677734] [G loss: -2962.222656]\n",
      "1193 [D loss: -14986.204102] [G loss: -3030.526367]\n",
      "1194 [D loss: -14981.007812] [G loss: -2881.606934]\n",
      "1195 [D loss: -14971.874023] [G loss: -2899.330811]\n",
      "1196 [D loss: -15049.149414] [G loss: -3046.829102]\n",
      "1197 [D loss: -15075.596680] [G loss: -2884.251221]\n",
      "1198 [D loss: -15026.500977] [G loss: -3020.441895]\n",
      "1199 [D loss: -15089.963867] [G loss: -2911.004639]\n",
      "1200 [D loss: -15095.510742] [G loss: -2819.878418]\n",
      "1201 [D loss: -15078.001953] [G loss: -2988.650391]\n",
      "1202 [D loss: -15130.165039] [G loss: -2940.965088]\n",
      "1203 [D loss: -15114.346680] [G loss: -2918.576660]\n",
      "1204 [D loss: -15226.831055] [G loss: -2898.699707]\n",
      "1205 [D loss: -15184.506836] [G loss: -2918.618164]\n",
      "1206 [D loss: -15255.129883] [G loss: -2984.647949]\n",
      "1207 [D loss: -15242.892578] [G loss: -3066.823242]\n",
      "1208 [D loss: -15157.496094] [G loss: -2952.808105]\n",
      "1209 [D loss: -15299.001953] [G loss: -2934.058594]\n",
      "1210 [D loss: -15355.353516] [G loss: -3116.661133]\n",
      "1211 [D loss: -15327.977539] [G loss: -2855.725098]\n",
      "1212 [D loss: -15286.699219] [G loss: -3186.463867]\n",
      "1213 [D loss: -15398.737305] [G loss: -3236.861328]\n",
      "1214 [D loss: -15369.686523] [G loss: -3203.218994]\n",
      "1215 [D loss: -15441.354492] [G loss: -3027.444336]\n",
      "1216 [D loss: -15359.136719] [G loss: -3136.686279]\n",
      "1217 [D loss: -15459.437500] [G loss: -2951.555664]\n",
      "1218 [D loss: -15477.484375] [G loss: -3156.777344]\n",
      "1219 [D loss: -15476.841797] [G loss: -3274.667725]\n",
      "1220 [D loss: -15451.727539] [G loss: -3003.854980]\n",
      "1221 [D loss: -15535.561523] [G loss: -3441.644775]\n",
      "1222 [D loss: -15526.090820] [G loss: -3158.257568]\n",
      "1223 [D loss: -15590.501953] [G loss: -3140.583740]\n",
      "1224 [D loss: -15557.336914] [G loss: -3239.078125]\n",
      "1225 [D loss: -15579.403320] [G loss: -2940.168213]\n",
      "1226 [D loss: -15602.772461] [G loss: -3291.046387]\n",
      "1227 [D loss: -15637.060547] [G loss: -3237.116699]\n",
      "1228 [D loss: -15661.198242] [G loss: -3408.826172]\n",
      "1229 [D loss: -15664.908203] [G loss: -3355.855225]\n",
      "1230 [D loss: -15656.489258] [G loss: -3473.583252]\n",
      "1231 [D loss: -15753.535156] [G loss: -3039.656738]\n",
      "1232 [D loss: -15750.242188] [G loss: -3310.569824]\n",
      "1233 [D loss: -15737.359375] [G loss: -3268.588623]\n",
      "1234 [D loss: -15741.033203] [G loss: -3023.199707]\n",
      "1235 [D loss: -15789.674805] [G loss: -3369.600586]\n",
      "1236 [D loss: -15800.827148] [G loss: -2953.640625]\n",
      "1237 [D loss: -15822.147461] [G loss: -3269.208496]\n",
      "1238 [D loss: -15840.393555] [G loss: -3424.961182]\n",
      "1239 [D loss: -15880.006836] [G loss: -3294.885010]\n",
      "1240 [D loss: -15858.828125] [G loss: -3391.075439]\n",
      "1241 [D loss: -15898.457031] [G loss: -3686.202148]\n",
      "1242 [D loss: -15888.787109] [G loss: -3161.795654]\n",
      "1243 [D loss: -15997.780273] [G loss: -3279.335938]\n",
      "1244 [D loss: -16005.456055] [G loss: -3503.462402]\n",
      "1245 [D loss: -16040.325195] [G loss: -3349.287598]\n",
      "1246 [D loss: -15980.842773] [G loss: -3197.840576]\n",
      "1247 [D loss: -15997.874023] [G loss: -3182.094238]\n",
      "1248 [D loss: -16014.034180] [G loss: -3164.886963]\n",
      "1249 [D loss: -15970.535156] [G loss: -3236.500977]\n",
      "1250 [D loss: -16106.947266] [G loss: -3265.483887]\n",
      "1251 [D loss: -16002.010742] [G loss: -3217.423828]\n",
      "1252 [D loss: -16186.457031] [G loss: -3341.376953]\n",
      "1253 [D loss: -16150.460938] [G loss: -3110.691650]\n",
      "1254 [D loss: -16206.741211] [G loss: -2641.531006]\n",
      "1255 [D loss: -16159.350586] [G loss: -3565.504395]\n",
      "1256 [D loss: -16196.061523] [G loss: -3405.250488]\n",
      "1257 [D loss: -16161.833984] [G loss: -3522.778076]\n",
      "1258 [D loss: -16217.188477] [G loss: -3347.107178]\n",
      "1259 [D loss: -16303.816406] [G loss: -3286.353760]\n",
      "1260 [D loss: -16249.296875] [G loss: -3515.675537]\n",
      "1261 [D loss: -16341.008789] [G loss: -3390.452148]\n",
      "1262 [D loss: -16323.511719] [G loss: -3350.732910]\n",
      "1263 [D loss: -16298.669922] [G loss: -3238.752930]\n",
      "1264 [D loss: -16297.782227] [G loss: -3316.152588]\n",
      "1265 [D loss: -16356.245117] [G loss: -3396.348633]\n",
      "1266 [D loss: -16420.863281] [G loss: -3308.433350]\n",
      "1267 [D loss: -16385.291016] [G loss: -3360.933105]\n",
      "1268 [D loss: -16369.223633] [G loss: -3593.200195]\n",
      "1269 [D loss: -16313.843750] [G loss: -3544.843506]\n",
      "1270 [D loss: -16474.708984] [G loss: -3493.700195]\n",
      "1271 [D loss: -16459.814453] [G loss: -3239.628174]\n",
      "1272 [D loss: -16538.501953] [G loss: -3605.431152]\n",
      "1273 [D loss: -16520.486328] [G loss: -3375.672363]\n",
      "1274 [D loss: -16583.474609] [G loss: -3383.399902]\n",
      "1275 [D loss: -16579.042969] [G loss: -3555.161133]\n",
      "1276 [D loss: -16614.281250] [G loss: -3496.438477]\n",
      "1277 [D loss: -16569.919922] [G loss: -3766.672363]\n",
      "1278 [D loss: -16607.058594] [G loss: -3565.681885]\n",
      "1279 [D loss: -16696.697266] [G loss: -3431.596680]\n",
      "1280 [D loss: -16626.578125] [G loss: -3653.331055]\n",
      "1281 [D loss: -16643.251953] [G loss: -3332.217041]\n",
      "1282 [D loss: -16732.476562] [G loss: -3612.533691]\n",
      "1283 [D loss: -16734.230469] [G loss: -3576.453613]\n",
      "1284 [D loss: -16722.771484] [G loss: -3273.537109]\n",
      "1285 [D loss: -16715.599609] [G loss: -3423.165283]\n",
      "1286 [D loss: -16870.068359] [G loss: -3389.637695]\n",
      "1287 [D loss: -16805.957031] [G loss: -3494.671143]\n",
      "1288 [D loss: -16870.371094] [G loss: -3385.841064]\n",
      "1289 [D loss: -16722.417969] [G loss: -3537.796631]\n",
      "1290 [D loss: -16843.181641] [G loss: -3499.831055]\n",
      "1291 [D loss: -16835.197266] [G loss: -3631.496582]\n",
      "1292 [D loss: -16814.796875] [G loss: -3915.480957]\n",
      "1293 [D loss: -16944.919922] [G loss: -3388.972656]\n",
      "1294 [D loss: -16934.988281] [G loss: -3396.171631]\n",
      "1295 [D loss: -16974.369141] [G loss: -3584.692871]\n",
      "1296 [D loss: -16970.949219] [G loss: -3354.998779]\n",
      "1297 [D loss: -17045.361328] [G loss: -3368.773438]\n",
      "1298 [D loss: -17018.050781] [G loss: -3703.735596]\n",
      "1299 [D loss: -17038.550781] [G loss: -3402.754395]\n",
      "1300 [D loss: -17091.244141] [G loss: -3520.315430]\n",
      "1301 [D loss: -17068.656250] [G loss: -3528.346191]\n",
      "1302 [D loss: -17025.587891] [G loss: -3710.447266]\n",
      "1303 [D loss: -17187.382812] [G loss: -3010.582520]\n",
      "1304 [D loss: -17170.359375] [G loss: -3451.180664]\n",
      "1305 [D loss: -17156.658203] [G loss: -3689.436523]\n",
      "1306 [D loss: -17190.492188] [G loss: -3676.840332]\n",
      "1307 [D loss: -17200.566406] [G loss: -3683.633789]\n",
      "1308 [D loss: -17243.970703] [G loss: -3765.708984]\n",
      "1309 [D loss: -17226.937500] [G loss: -3686.516602]\n",
      "1310 [D loss: -17347.748047] [G loss: -3720.968506]\n",
      "1311 [D loss: -17305.826172] [G loss: -3699.429688]\n",
      "1312 [D loss: -17343.845703] [G loss: -3793.335449]\n",
      "1313 [D loss: -17336.498047] [G loss: -3851.444336]\n",
      "1314 [D loss: -17134.349609] [G loss: -3880.329590]\n",
      "1315 [D loss: -17369.416016] [G loss: -3922.568604]\n",
      "1316 [D loss: -17452.283203] [G loss: -3530.244141]\n",
      "1317 [D loss: -17358.664062] [G loss: -3542.877441]\n",
      "1318 [D loss: -17447.583984] [G loss: -3796.797852]\n",
      "1319 [D loss: -17452.859375] [G loss: -3858.442383]\n",
      "1320 [D loss: -17504.101562] [G loss: -3271.544922]\n",
      "1321 [D loss: -17468.451172] [G loss: -3537.763672]\n",
      "1322 [D loss: -17443.578125] [G loss: -3594.993652]\n",
      "1323 [D loss: -17508.576172] [G loss: -3522.506348]\n",
      "1324 [D loss: -17609.841797] [G loss: -3889.606689]\n",
      "1325 [D loss: -17559.794922] [G loss: -3828.153809]\n",
      "1326 [D loss: -17561.892578] [G loss: -3955.584717]\n",
      "1327 [D loss: -17478.482422] [G loss: -3939.855225]\n",
      "1328 [D loss: -17598.771484] [G loss: -3720.301514]\n",
      "1329 [D loss: -17655.208984] [G loss: -3678.214844]\n",
      "1330 [D loss: -17653.351562] [G loss: -3745.079834]\n",
      "1331 [D loss: -17722.716797] [G loss: -3765.389648]\n",
      "1332 [D loss: -17677.564453] [G loss: -3705.096191]\n",
      "1333 [D loss: -17714.085938] [G loss: -3926.241455]\n",
      "1334 [D loss: -17656.912109] [G loss: -3715.632812]\n",
      "1335 [D loss: -17773.644531] [G loss: -3881.201416]\n",
      "1336 [D loss: -17727.304688] [G loss: -3923.201172]\n",
      "1337 [D loss: -17886.416016] [G loss: -3940.164795]\n",
      "1338 [D loss: -17853.812500] [G loss: -3840.474854]\n",
      "1339 [D loss: -17856.050781] [G loss: -3805.393066]\n",
      "1340 [D loss: -17917.625000] [G loss: -3505.056152]\n",
      "1341 [D loss: -17858.929688] [G loss: -3751.974121]\n",
      "1342 [D loss: -17872.287109] [G loss: -3939.522949]\n",
      "1343 [D loss: -17929.976562] [G loss: -3803.774658]\n",
      "1344 [D loss: -17996.917969] [G loss: -3887.424805]\n",
      "1345 [D loss: -17901.818359] [G loss: -4144.257812]\n",
      "1346 [D loss: -18004.880859] [G loss: -3986.880371]\n",
      "1347 [D loss: -17980.435547] [G loss: -3889.254395]\n",
      "1348 [D loss: -18066.640625] [G loss: -3837.005371]\n",
      "1349 [D loss: -18024.167969] [G loss: -3710.623535]\n",
      "1350 [D loss: -18153.515625] [G loss: -3904.510254]\n",
      "1351 [D loss: -18085.650391] [G loss: -3895.338379]\n",
      "1352 [D loss: -18114.394531] [G loss: -3999.711914]\n",
      "1353 [D loss: -18196.548828] [G loss: -4032.659668]\n",
      "1354 [D loss: -18191.976562] [G loss: -4014.420654]\n",
      "1355 [D loss: -18239.148438] [G loss: -4267.785156]\n",
      "1356 [D loss: -18231.181641] [G loss: -4022.710938]\n",
      "1357 [D loss: -18204.214844] [G loss: -4191.687012]\n",
      "1358 [D loss: -18298.666016] [G loss: -3810.986816]\n",
      "1359 [D loss: -18233.515625] [G loss: -3904.119141]\n",
      "1360 [D loss: -18242.626953] [G loss: -3608.056885]\n",
      "1361 [D loss: -18295.041016] [G loss: -4199.611816]\n",
      "1362 [D loss: -18337.375000] [G loss: -4019.897461]\n",
      "1363 [D loss: -18382.505859] [G loss: -3957.426270]\n",
      "1364 [D loss: -18335.003906] [G loss: -4019.100098]\n",
      "1365 [D loss: -18371.818359] [G loss: -3956.188477]\n",
      "1366 [D loss: -18445.509766] [G loss: -4112.751953]\n",
      "1367 [D loss: -18486.101562] [G loss: -3965.770508]\n",
      "1368 [D loss: -18493.648438] [G loss: -4155.166016]\n",
      "1369 [D loss: -18532.001953] [G loss: -4027.973633]\n",
      "1370 [D loss: -18464.412109] [G loss: -4017.939697]\n",
      "1371 [D loss: -18425.964844] [G loss: -3997.692871]\n",
      "1372 [D loss: -18520.322266] [G loss: -4039.964844]\n",
      "1373 [D loss: -18552.960938] [G loss: -3786.733398]\n",
      "1374 [D loss: -18528.833984] [G loss: -3898.284912]\n",
      "1375 [D loss: -18627.111328] [G loss: -4279.855957]\n",
      "1376 [D loss: -18654.595703] [G loss: -4269.773438]\n",
      "1377 [D loss: -18661.179688] [G loss: -3988.107666]\n",
      "1378 [D loss: -18650.085938] [G loss: -4030.626221]\n",
      "1379 [D loss: -18683.080078] [G loss: -4015.948242]\n",
      "1380 [D loss: -18701.089844] [G loss: -3821.902832]\n",
      "1381 [D loss: -18728.109375] [G loss: -4190.102539]\n",
      "1382 [D loss: -18786.720703] [G loss: -4369.553711]\n",
      "1383 [D loss: -18802.525391] [G loss: -4517.739258]\n",
      "1384 [D loss: -18777.316406] [G loss: -3964.409668]\n",
      "1385 [D loss: -18829.224609] [G loss: -4324.328125]\n",
      "1386 [D loss: -18843.779297] [G loss: -4118.589844]\n",
      "1387 [D loss: -18868.851562] [G loss: -4165.500977]\n",
      "1388 [D loss: -18824.707031] [G loss: -4121.410156]\n",
      "1389 [D loss: -18874.396484] [G loss: -4093.904785]\n",
      "1390 [D loss: -18807.755859] [G loss: -4116.676758]\n",
      "1391 [D loss: -18966.900391] [G loss: -4326.217773]\n",
      "1392 [D loss: -18864.730469] [G loss: -4444.309570]\n",
      "1393 [D loss: -19022.339844] [G loss: -4282.129883]\n",
      "1394 [D loss: -18888.234375] [G loss: -4410.002441]\n",
      "1395 [D loss: -19028.781250] [G loss: -4250.823242]\n",
      "1396 [D loss: -18987.828125] [G loss: -4137.941406]\n",
      "1397 [D loss: -19115.857422] [G loss: -4143.772949]\n",
      "1398 [D loss: -19057.208984] [G loss: -4253.403320]\n",
      "1399 [D loss: -19073.404297] [G loss: -4272.786133]\n",
      "1400 [D loss: -19106.355469] [G loss: -4320.776367]\n",
      "1401 [D loss: -19081.154297] [G loss: -4436.964355]\n",
      "1402 [D loss: -19170.968750] [G loss: -4343.066406]\n",
      "1403 [D loss: -19171.064453] [G loss: -4133.977539]\n",
      "1404 [D loss: -19148.794922] [G loss: -4353.617188]\n",
      "1405 [D loss: -19231.308594] [G loss: -4131.756836]\n",
      "1406 [D loss: -19236.054688] [G loss: -4157.536133]\n",
      "1407 [D loss: -19289.523438] [G loss: -4565.436523]\n",
      "1408 [D loss: -19270.951172] [G loss: -4323.620117]\n",
      "1409 [D loss: -19296.191406] [G loss: -4108.575195]\n",
      "1410 [D loss: -19316.898438] [G loss: -4517.961914]\n",
      "1411 [D loss: -19344.019531] [G loss: -4068.798096]\n",
      "1412 [D loss: -19290.748047] [G loss: -4427.750000]\n",
      "1413 [D loss: -19331.718750] [G loss: -4157.551758]\n",
      "1414 [D loss: -19384.111328] [G loss: -4337.192871]\n",
      "1415 [D loss: -19418.291016] [G loss: -4315.736328]\n",
      "1416 [D loss: -19334.478516] [G loss: -4344.388184]\n",
      "1417 [D loss: -19512.751953] [G loss: -4452.350586]\n",
      "1418 [D loss: -19484.632812] [G loss: -4201.318848]\n",
      "1419 [D loss: -19577.089844] [G loss: -4277.471680]\n",
      "1420 [D loss: -19553.974609] [G loss: -4260.603516]\n",
      "1421 [D loss: -19546.533203] [G loss: -4319.404297]\n",
      "1422 [D loss: -19592.939453] [G loss: -4471.694336]\n",
      "1423 [D loss: -19597.029297] [G loss: -4520.703125]\n",
      "1424 [D loss: -19629.962891] [G loss: -4347.564453]\n",
      "1425 [D loss: -19485.640625] [G loss: -4175.724609]\n",
      "1426 [D loss: -19655.060547] [G loss: -4374.808594]\n",
      "1427 [D loss: -19616.691406] [G loss: -4285.247070]\n",
      "1428 [D loss: -19647.984375] [G loss: -4676.216797]\n",
      "1429 [D loss: -19735.205078] [G loss: -4334.178223]\n",
      "1430 [D loss: -19748.265625] [G loss: -4189.541504]\n",
      "1431 [D loss: -19693.117188] [G loss: -4374.454102]\n",
      "1432 [D loss: -19732.134766] [G loss: -4494.010742]\n",
      "1433 [D loss: -19722.644531] [G loss: -4239.408203]\n",
      "1434 [D loss: -19854.962891] [G loss: -4320.147461]\n",
      "1435 [D loss: -19875.546875] [G loss: -4823.237305]\n",
      "1436 [D loss: -19850.710938] [G loss: -4564.507812]\n",
      "1437 [D loss: -19878.378906] [G loss: -4323.944824]\n",
      "1438 [D loss: -19945.433594] [G loss: -4607.564453]\n",
      "1439 [D loss: -19956.824219] [G loss: -4301.381836]\n",
      "1440 [D loss: -19943.150391] [G loss: -4670.258789]\n",
      "1441 [D loss: -19974.326172] [G loss: -4429.716797]\n",
      "1442 [D loss: -20047.828125] [G loss: -4478.533203]\n",
      "1443 [D loss: -19954.726562] [G loss: -4583.302734]\n",
      "1444 [D loss: -20006.318359] [G loss: -4841.457520]\n",
      "1445 [D loss: -20100.914062] [G loss: -4972.622070]\n",
      "1446 [D loss: -20100.992188] [G loss: -4702.942383]\n",
      "1447 [D loss: -20092.414062] [G loss: -4872.661133]\n",
      "1448 [D loss: -20114.867188] [G loss: -4703.458008]\n",
      "1449 [D loss: -20135.845703] [G loss: -4670.706055]\n",
      "1450 [D loss: -20167.300781] [G loss: -4608.322266]\n",
      "1451 [D loss: -20144.027344] [G loss: -4242.646484]\n",
      "1452 [D loss: -20150.849609] [G loss: -4771.527832]\n",
      "1453 [D loss: -20195.359375] [G loss: -4450.147949]\n",
      "1454 [D loss: -20208.234375] [G loss: -4754.256836]\n",
      "1455 [D loss: -20242.630859] [G loss: -4656.692871]\n",
      "1456 [D loss: -20225.589844] [G loss: -4499.669434]\n",
      "1457 [D loss: -20334.638672] [G loss: -4826.695312]\n",
      "1458 [D loss: -20308.144531] [G loss: -4611.803711]\n",
      "1459 [D loss: -20407.058594] [G loss: -4851.898438]\n",
      "1460 [D loss: -20395.423828] [G loss: -4763.736328]\n",
      "1461 [D loss: -20469.822266] [G loss: -4297.851562]\n",
      "1462 [D loss: -20443.068359] [G loss: -4754.488281]\n",
      "1463 [D loss: -20495.072266] [G loss: -4443.058594]\n",
      "1464 [D loss: -20413.365234] [G loss: -4743.932617]\n",
      "1465 [D loss: -20433.544922] [G loss: -4592.963867]\n",
      "1466 [D loss: -20546.210938] [G loss: -4898.959473]\n",
      "1467 [D loss: -20527.349609] [G loss: -4782.462402]\n",
      "1468 [D loss: -20554.878906] [G loss: -4990.452148]\n",
      "1469 [D loss: -20528.455078] [G loss: -4684.503906]\n",
      "1470 [D loss: -20607.960938] [G loss: -4572.418945]\n",
      "1471 [D loss: -20564.689453] [G loss: -4559.748047]\n",
      "1472 [D loss: -20673.042969] [G loss: -4423.834473]\n",
      "1473 [D loss: -20628.781250] [G loss: -4876.347656]\n",
      "1474 [D loss: -20667.822266] [G loss: -4716.667969]\n",
      "1475 [D loss: -20684.962891] [G loss: -4618.938965]\n",
      "1476 [D loss: -20680.394531] [G loss: -4800.380859]\n",
      "1477 [D loss: -20786.722656] [G loss: -4572.538086]\n",
      "1478 [D loss: -20728.937500] [G loss: -5100.299316]\n",
      "1479 [D loss: -20806.832031] [G loss: -4607.990723]\n",
      "1480 [D loss: -20812.804688] [G loss: -4874.208008]\n",
      "1481 [D loss: -20851.353516] [G loss: -5001.125977]\n",
      "1482 [D loss: -20875.115234] [G loss: -4683.932617]\n",
      "1483 [D loss: -20925.121094] [G loss: -4204.604492]\n",
      "1484 [D loss: -20799.062500] [G loss: -5049.924316]\n",
      "1485 [D loss: -20922.730469] [G loss: -4718.018555]\n",
      "1486 [D loss: -20998.953125] [G loss: -4804.914062]\n",
      "1487 [D loss: -20959.250000] [G loss: -4930.145508]\n",
      "1488 [D loss: -20979.820312] [G loss: -4513.785156]\n",
      "1489 [D loss: -21025.822266] [G loss: -4835.011719]\n",
      "1490 [D loss: -21020.230469] [G loss: -4909.621094]\n",
      "1491 [D loss: -20924.156250] [G loss: -4771.087891]\n",
      "1492 [D loss: -21084.164062] [G loss: -4749.819336]\n",
      "1493 [D loss: -21101.027344] [G loss: -4794.179688]\n",
      "1494 [D loss: -21125.242188] [G loss: -4604.315430]\n",
      "1495 [D loss: -21114.576172] [G loss: -4858.317383]\n",
      "1496 [D loss: -21141.683594] [G loss: -5054.445312]\n",
      "1497 [D loss: -21171.462891] [G loss: -4610.794434]\n",
      "1498 [D loss: -21127.488281] [G loss: -4884.603516]\n",
      "1499 [D loss: -20976.792969] [G loss: -4695.213867]\n",
      "1500 [D loss: -21255.263672] [G loss: -4775.770508]\n",
      "1501 [D loss: -21285.208984] [G loss: -4950.179688]\n",
      "1502 [D loss: -21285.566406] [G loss: -5058.272949]\n",
      "1503 [D loss: -21294.164062] [G loss: -4974.996094]\n",
      "1504 [D loss: -21356.640625] [G loss: -5229.263672]\n",
      "1505 [D loss: -21408.523438] [G loss: -4761.753906]\n",
      "1506 [D loss: -21328.099609] [G loss: -5301.534180]\n",
      "1507 [D loss: -21407.933594] [G loss: -4717.330566]\n",
      "1508 [D loss: -21289.962891] [G loss: -5148.062500]\n",
      "1509 [D loss: -21361.298828] [G loss: -4526.627930]\n",
      "1510 [D loss: -21433.300781] [G loss: -4772.394043]\n",
      "1511 [D loss: -21474.212891] [G loss: -4805.039062]\n",
      "1512 [D loss: -21595.296875] [G loss: -4727.759766]\n",
      "1513 [D loss: -21469.457031] [G loss: -5032.874023]\n",
      "1514 [D loss: -21440.976562] [G loss: -5232.506348]\n",
      "1515 [D loss: -21636.029297] [G loss: -4721.663086]\n",
      "1516 [D loss: -21597.861328] [G loss: -4916.287598]\n",
      "1517 [D loss: -21550.646484] [G loss: -4431.284668]\n",
      "1518 [D loss: -21657.099609] [G loss: -5177.101562]\n",
      "1519 [D loss: -21657.593750] [G loss: -4905.991211]\n",
      "1520 [D loss: -21634.158203] [G loss: -5141.408691]\n",
      "1521 [D loss: -21656.960938] [G loss: -4805.772461]\n",
      "1522 [D loss: -21726.863281] [G loss: -4664.054199]\n",
      "1523 [D loss: -21732.945312] [G loss: -4739.531250]\n",
      "1524 [D loss: -21760.919922] [G loss: -4805.504395]\n",
      "1525 [D loss: -21840.939453] [G loss: -4984.380859]\n",
      "1526 [D loss: -21820.484375] [G loss: -4931.565430]\n",
      "1527 [D loss: -21742.365234] [G loss: -5175.746582]\n",
      "1528 [D loss: -21840.132812] [G loss: -5142.862793]\n",
      "1529 [D loss: -21860.091797] [G loss: -4823.397461]\n",
      "1530 [D loss: -21886.097656] [G loss: -4984.857422]\n",
      "1531 [D loss: -21856.480469] [G loss: -5250.476562]\n",
      "1532 [D loss: -21901.994141] [G loss: -5206.772461]\n",
      "1533 [D loss: -21955.644531] [G loss: -5226.677734]\n",
      "1534 [D loss: -21946.322266] [G loss: -4927.094238]\n",
      "1535 [D loss: -22034.728516] [G loss: -5476.408203]\n",
      "1536 [D loss: -21895.158203] [G loss: -4907.138672]\n",
      "1537 [D loss: -21989.064453] [G loss: -5295.293945]\n",
      "1538 [D loss: -22003.941406] [G loss: -5353.299805]\n",
      "1539 [D loss: -21984.367188] [G loss: -4878.715820]\n",
      "1540 [D loss: -22116.705078] [G loss: -5210.523438]\n",
      "1541 [D loss: -22217.148438] [G loss: -4931.465332]\n",
      "1542 [D loss: -22195.730469] [G loss: -5048.459473]\n",
      "1543 [D loss: -22173.236328] [G loss: -5013.030273]\n",
      "1544 [D loss: -22094.125000] [G loss: -5658.108887]\n",
      "1545 [D loss: -22265.060547] [G loss: -5110.098633]\n",
      "1546 [D loss: -22236.123047] [G loss: -5516.254883]\n",
      "1547 [D loss: -22290.695312] [G loss: -5162.971680]\n",
      "1548 [D loss: -22189.603516] [G loss: -5489.176758]\n",
      "1549 [D loss: -22326.519531] [G loss: -5187.992188]\n",
      "1550 [D loss: -22339.335938] [G loss: -5301.785156]\n",
      "1551 [D loss: -22361.636719] [G loss: -4923.727051]\n",
      "1552 [D loss: -22325.656250] [G loss: -5213.245605]\n",
      "1553 [D loss: -22406.244141] [G loss: -5135.509766]\n",
      "1554 [D loss: -22424.857422] [G loss: -5345.614746]\n",
      "1555 [D loss: -22456.824219] [G loss: -5347.644531]\n",
      "1556 [D loss: -22415.216797] [G loss: -5170.733398]\n",
      "1557 [D loss: -22557.140625] [G loss: -5044.649414]\n",
      "1558 [D loss: -22586.589844] [G loss: -5364.137207]\n",
      "1559 [D loss: -22537.875000] [G loss: -4959.061523]\n",
      "1560 [D loss: -22528.460938] [G loss: -4794.246094]\n",
      "1561 [D loss: -22592.009766] [G loss: -5423.069336]\n",
      "1562 [D loss: -22621.583984] [G loss: -4891.135254]\n",
      "1563 [D loss: -22658.796875] [G loss: -5421.026367]\n",
      "1564 [D loss: -22681.253906] [G loss: -5420.430664]\n",
      "1565 [D loss: -22676.707031] [G loss: -4986.022461]\n",
      "1566 [D loss: -22720.601562] [G loss: -5309.749023]\n",
      "1567 [D loss: -22785.193359] [G loss: -5668.255859]\n",
      "1568 [D loss: -22659.234375] [G loss: -5280.602051]\n",
      "1569 [D loss: -22799.744141] [G loss: -5358.083008]\n",
      "1570 [D loss: -22741.998047] [G loss: -4628.645020]\n",
      "1571 [D loss: -22770.292969] [G loss: -4913.757812]\n",
      "1572 [D loss: -22827.052734] [G loss: -5115.499023]\n",
      "1573 [D loss: -22838.398438] [G loss: -5378.765137]\n",
      "1574 [D loss: -22922.970703] [G loss: -4883.720703]\n",
      "1575 [D loss: -22854.015625] [G loss: -5468.134766]\n",
      "1576 [D loss: -22777.478516] [G loss: -5321.473633]\n",
      "1577 [D loss: -23016.833984] [G loss: -5080.339844]\n",
      "1578 [D loss: -22979.089844] [G loss: -5314.550781]\n",
      "1579 [D loss: -23040.843750] [G loss: -5306.276367]\n",
      "1580 [D loss: -22980.238281] [G loss: -5043.076172]\n",
      "1581 [D loss: -23023.722656] [G loss: -5422.542480]\n",
      "1582 [D loss: -22958.603516] [G loss: -5619.486328]\n",
      "1583 [D loss: -23015.099609] [G loss: -5510.814941]\n",
      "1584 [D loss: -23142.302734] [G loss: -5189.609375]\n",
      "1585 [D loss: -23038.431641] [G loss: -5484.104980]\n",
      "1586 [D loss: -23167.689453] [G loss: -5402.426270]\n",
      "1587 [D loss: -23155.794922] [G loss: -5403.356934]\n",
      "1588 [D loss: -23111.876953] [G loss: -5436.542969]\n",
      "1589 [D loss: -23188.556641] [G loss: -5735.632812]\n",
      "1590 [D loss: -23135.373047] [G loss: -5161.032715]\n",
      "1591 [D loss: -23193.945312] [G loss: -5512.679688]\n",
      "1592 [D loss: -23299.066406] [G loss: -5484.254883]\n",
      "1593 [D loss: -23293.933594] [G loss: -5798.764160]\n",
      "1594 [D loss: -23308.501953] [G loss: -5820.254395]\n",
      "1595 [D loss: -23356.048828] [G loss: -5719.360352]\n",
      "1596 [D loss: -23261.498047] [G loss: -5615.490234]\n",
      "1597 [D loss: -23333.214844] [G loss: -5777.600586]\n",
      "1598 [D loss: -23399.015625] [G loss: -5179.760742]\n",
      "1599 [D loss: -23466.220703] [G loss: -5744.791992]\n",
      "1600 [D loss: -23425.640625] [G loss: -5771.800781]\n",
      "1601 [D loss: -23467.677734] [G loss: -5970.405273]\n",
      "1602 [D loss: -23532.056641] [G loss: -5809.969727]\n",
      "1603 [D loss: -23425.707031] [G loss: -5010.400879]\n",
      "1604 [D loss: -23494.242188] [G loss: -5209.025391]\n",
      "1605 [D loss: -23638.904297] [G loss: -5593.315430]\n",
      "1606 [D loss: -23576.263672] [G loss: -5299.388672]\n",
      "1607 [D loss: -23603.017578] [G loss: -5426.915039]\n",
      "1608 [D loss: -23480.498047] [G loss: -5409.848145]\n",
      "1609 [D loss: -23582.158203] [G loss: -5474.555664]\n",
      "1610 [D loss: -23547.636719] [G loss: -5381.626465]\n",
      "1611 [D loss: -23673.531250] [G loss: -5601.177734]\n",
      "1612 [D loss: -23755.222656] [G loss: -5546.372070]\n",
      "1613 [D loss: -23713.634766] [G loss: -5667.839355]\n",
      "1614 [D loss: -23754.439453] [G loss: -5340.063965]\n",
      "1615 [D loss: -23732.925781] [G loss: -5648.628418]\n",
      "1616 [D loss: -23753.277344] [G loss: -5628.826172]\n",
      "1617 [D loss: -23747.652344] [G loss: -5844.274414]\n",
      "1618 [D loss: -23725.392578] [G loss: -5546.139648]\n",
      "1619 [D loss: -23837.150391] [G loss: -5161.114258]\n",
      "1620 [D loss: -23919.312500] [G loss: -5544.412598]\n",
      "1621 [D loss: -23878.386719] [G loss: -5547.154785]\n",
      "1622 [D loss: -23969.621094] [G loss: -5627.970703]\n",
      "1623 [D loss: -24011.701172] [G loss: -5609.864258]\n",
      "1624 [D loss: -23962.812500] [G loss: -5263.133301]\n",
      "1625 [D loss: -24036.087891] [G loss: -5895.906250]\n",
      "1626 [D loss: -24029.791016] [G loss: -5621.633789]\n",
      "1627 [D loss: -24041.160156] [G loss: -5472.939453]\n",
      "1628 [D loss: -24062.384766] [G loss: -5558.917969]\n",
      "1629 [D loss: -24040.003906] [G loss: -5632.435547]\n",
      "1630 [D loss: -24115.464844] [G loss: -5319.055664]\n",
      "1631 [D loss: -24130.205078] [G loss: -5081.229492]\n",
      "1632 [D loss: -24142.216797] [G loss: -6162.361328]\n",
      "1633 [D loss: -24159.429688] [G loss: -6001.467285]\n",
      "1634 [D loss: -24215.447266] [G loss: -5520.734863]\n",
      "1635 [D loss: -24227.412109] [G loss: -5520.406250]\n",
      "1636 [D loss: -24189.458984] [G loss: -5883.626953]\n",
      "1637 [D loss: -24217.367188] [G loss: -5744.066406]\n",
      "1638 [D loss: -24238.160156] [G loss: -5379.881836]\n",
      "1639 [D loss: -24335.128906] [G loss: -5913.617188]\n",
      "1640 [D loss: -24330.605469] [G loss: -5932.280273]\n",
      "1641 [D loss: -24385.541016] [G loss: -5354.208008]\n",
      "1642 [D loss: -24405.414062] [G loss: -5853.402344]\n",
      "1643 [D loss: -24450.408203] [G loss: -5840.652344]\n",
      "1644 [D loss: -24506.185547] [G loss: -6052.622070]\n",
      "1645 [D loss: -24489.564453] [G loss: -5660.342773]\n",
      "1646 [D loss: -24357.404297] [G loss: -5548.444824]\n",
      "1647 [D loss: -24568.205078] [G loss: -5932.486328]\n",
      "1648 [D loss: -24481.187500] [G loss: -5676.706543]\n",
      "1649 [D loss: -24562.367188] [G loss: -5946.330566]\n",
      "1650 [D loss: -24600.058594] [G loss: -5819.141602]\n",
      "1651 [D loss: -24523.648438] [G loss: -5961.607422]\n",
      "1652 [D loss: -24533.908203] [G loss: -5807.406250]\n",
      "1653 [D loss: -24659.150391] [G loss: -6270.190918]\n",
      "1654 [D loss: -24654.277344] [G loss: -5846.324707]\n",
      "1655 [D loss: -24701.871094] [G loss: -6201.648926]\n",
      "1656 [D loss: -24728.804688] [G loss: -6068.848633]\n",
      "1657 [D loss: -24765.085938] [G loss: -5953.236328]\n",
      "1658 [D loss: -24818.812500] [G loss: -6245.919922]\n",
      "1659 [D loss: -24761.669922] [G loss: -5961.668945]\n",
      "1660 [D loss: -24781.677734] [G loss: -6128.902344]\n",
      "1661 [D loss: -24743.193359] [G loss: -5723.197266]\n",
      "1662 [D loss: -24768.894531] [G loss: -6070.683594]\n",
      "1663 [D loss: -24877.593750] [G loss: -5958.232422]\n",
      "1664 [D loss: -24941.792969] [G loss: -5505.844238]\n",
      "1665 [D loss: -24905.914062] [G loss: -5993.999023]\n",
      "1666 [D loss: -24967.460938] [G loss: -6041.588867]\n",
      "1667 [D loss: -24929.794922] [G loss: -6031.800781]\n",
      "1668 [D loss: -24961.445312] [G loss: -5932.236328]\n",
      "1669 [D loss: -24995.859375] [G loss: -5972.791016]\n",
      "1670 [D loss: -24999.214844] [G loss: -6191.673828]\n",
      "1671 [D loss: -25088.039062] [G loss: -5987.359375]\n",
      "1672 [D loss: -25096.656250] [G loss: -6168.762695]\n",
      "1673 [D loss: -25132.896484] [G loss: -5704.768066]\n",
      "1674 [D loss: -25143.142578] [G loss: -6182.209961]\n",
      "1675 [D loss: -25065.587891] [G loss: -6006.024414]\n",
      "1676 [D loss: -25132.923828] [G loss: -6083.942383]\n",
      "1677 [D loss: -25278.970703] [G loss: -5855.976074]\n",
      "1678 [D loss: -25283.398438] [G loss: -5857.172852]\n",
      "1679 [D loss: -25240.396484] [G loss: -6320.520508]\n",
      "1680 [D loss: -25248.056641] [G loss: -5910.037109]\n",
      "1681 [D loss: -25196.218750] [G loss: -5771.795410]\n",
      "1682 [D loss: -25372.757812] [G loss: -6188.332031]\n",
      "1683 [D loss: -25317.591797] [G loss: -6371.452148]\n",
      "1684 [D loss: -25358.224609] [G loss: -5978.068359]\n",
      "1685 [D loss: -25285.306641] [G loss: -6027.550781]\n",
      "1686 [D loss: -25285.197266] [G loss: -6187.592773]\n",
      "1687 [D loss: -25458.833984] [G loss: -5900.307129]\n",
      "1688 [D loss: -25405.964844] [G loss: -5916.929688]\n",
      "1689 [D loss: -25480.152344] [G loss: -5890.014160]\n",
      "1690 [D loss: -25487.351562] [G loss: -5762.765625]\n",
      "1691 [D loss: -25540.832031] [G loss: -6066.618164]\n",
      "1692 [D loss: -25460.341797] [G loss: -5873.328125]\n",
      "1693 [D loss: -25552.751953] [G loss: -6799.235352]\n",
      "1694 [D loss: -25637.070312] [G loss: -6451.545410]\n",
      "1695 [D loss: -25578.683594] [G loss: -6589.630371]\n",
      "1696 [D loss: -25550.111328] [G loss: -6206.134766]\n",
      "1697 [D loss: -25651.062500] [G loss: -6276.367188]\n",
      "1698 [D loss: -25678.103516] [G loss: -6200.158203]\n",
      "1699 [D loss: -25685.494141] [G loss: -6042.502930]\n",
      "1700 [D loss: -25675.562500] [G loss: -5809.022949]\n",
      "1701 [D loss: -25824.859375] [G loss: -6355.329102]\n",
      "1702 [D loss: -25666.716797] [G loss: -6189.653320]\n",
      "1703 [D loss: -25840.572266] [G loss: -5661.337891]\n",
      "1704 [D loss: -25837.253906] [G loss: -5634.382812]\n",
      "1705 [D loss: -25814.730469] [G loss: -5427.583008]\n",
      "1706 [D loss: -25909.230469] [G loss: -6476.517578]\n",
      "1707 [D loss: -25920.835938] [G loss: -6068.346680]\n",
      "1708 [D loss: -25839.054688] [G loss: -6338.585938]\n",
      "1709 [D loss: -25987.380859] [G loss: -6331.355469]\n",
      "1710 [D loss: -25998.142578] [G loss: -6521.852539]\n",
      "1711 [D loss: -25947.763672] [G loss: -5791.791992]\n",
      "1712 [D loss: -26072.035156] [G loss: -6310.059570]\n",
      "1713 [D loss: -26051.515625] [G loss: -6567.736328]\n",
      "1714 [D loss: -26043.900391] [G loss: -6403.422852]\n",
      "1715 [D loss: -26100.457031] [G loss: -6338.290039]\n",
      "1716 [D loss: -26015.369141] [G loss: -6436.511230]\n",
      "1717 [D loss: -26128.519531] [G loss: -6480.959961]\n",
      "1718 [D loss: -26168.476562] [G loss: -6458.467773]\n",
      "1719 [D loss: -26115.021484] [G loss: -6148.828125]\n",
      "1720 [D loss: -26127.089844] [G loss: -5928.404785]\n",
      "1721 [D loss: -26241.009766] [G loss: -6174.977539]\n",
      "1722 [D loss: -26219.734375] [G loss: -5922.964844]\n",
      "1723 [D loss: -26321.644531] [G loss: -5908.275879]\n",
      "1724 [D loss: -26369.857422] [G loss: -6295.257812]\n",
      "1725 [D loss: -26342.779297] [G loss: -5999.035156]\n",
      "1726 [D loss: -26354.154297] [G loss: -6162.484375]\n",
      "1727 [D loss: -26401.046875] [G loss: -6384.196289]\n",
      "1728 [D loss: -26383.042969] [G loss: -6384.048828]\n",
      "1729 [D loss: -26384.140625] [G loss: -6455.925293]\n",
      "1730 [D loss: -26418.291016] [G loss: -5962.204590]\n",
      "1731 [D loss: -26479.363281] [G loss: -6507.935059]\n",
      "1732 [D loss: -26457.921875] [G loss: -6129.853027]\n",
      "1733 [D loss: -26479.224609] [G loss: -6352.135742]\n",
      "1734 [D loss: -26594.796875] [G loss: -6342.994141]\n",
      "1735 [D loss: -26530.812500] [G loss: -6507.956543]\n",
      "1736 [D loss: -26637.023438] [G loss: -5932.628906]\n",
      "1737 [D loss: -26520.525391] [G loss: -5935.354980]\n",
      "1738 [D loss: -26472.511719] [G loss: -5955.208008]\n",
      "1739 [D loss: -26556.121094] [G loss: -6659.517578]\n",
      "1740 [D loss: -26665.865234] [G loss: -6291.791504]\n",
      "1741 [D loss: -26694.164062] [G loss: -6632.700195]\n",
      "1742 [D loss: -26680.492188] [G loss: -6555.537109]\n",
      "1743 [D loss: -26679.972656] [G loss: -6359.668945]\n",
      "1744 [D loss: -26747.982422] [G loss: -6413.325684]\n",
      "1745 [D loss: -26865.501953] [G loss: -6034.292480]\n",
      "1746 [D loss: -26885.546875] [G loss: -6469.664062]\n",
      "1747 [D loss: -26754.425781] [G loss: -6794.496094]\n",
      "1748 [D loss: -26839.339844] [G loss: -6591.076660]\n",
      "1749 [D loss: -26867.203125] [G loss: -6303.856445]\n",
      "1750 [D loss: -26829.876953] [G loss: -6791.039062]\n",
      "1751 [D loss: -26967.003906] [G loss: -6561.805176]\n",
      "1752 [D loss: -26968.222656] [G loss: -6506.765625]\n",
      "1753 [D loss: -26903.203125] [G loss: -6110.500488]\n",
      "1754 [D loss: -27068.986328] [G loss: -6291.041504]\n",
      "1755 [D loss: -27074.410156] [G loss: -6684.972656]\n",
      "1756 [D loss: -27071.775391] [G loss: -6900.801758]\n",
      "1757 [D loss: -27084.033203] [G loss: -6425.630371]\n",
      "1758 [D loss: -27046.552734] [G loss: -6367.296875]\n",
      "1759 [D loss: -27021.255859] [G loss: -5953.965820]\n",
      "1760 [D loss: -27173.601562] [G loss: -6670.728516]\n",
      "1761 [D loss: -27288.275391] [G loss: -6674.454102]\n",
      "1762 [D loss: -27254.812500] [G loss: -6931.954102]\n",
      "1763 [D loss: -27198.619141] [G loss: -6630.860352]\n",
      "1764 [D loss: -27223.697266] [G loss: -6391.333984]\n",
      "1765 [D loss: -27328.660156] [G loss: -6539.891602]\n",
      "1766 [D loss: -27251.476562] [G loss: -6478.141602]\n",
      "1767 [D loss: -27361.826172] [G loss: -6273.088867]\n",
      "1768 [D loss: -27345.796875] [G loss: -6751.309570]\n",
      "1769 [D loss: -27382.476562] [G loss: -6675.280273]\n",
      "1770 [D loss: -27421.765625] [G loss: -6626.913574]\n",
      "1771 [D loss: -27372.876953] [G loss: -6868.007812]\n",
      "1772 [D loss: -27484.830078] [G loss: -6853.265625]\n",
      "1773 [D loss: -27415.232422] [G loss: -6875.450195]\n",
      "1774 [D loss: -27484.808594] [G loss: -6803.310547]\n",
      "1775 [D loss: -27615.923828] [G loss: -6488.370605]\n",
      "1776 [D loss: -27524.345703] [G loss: -6788.958008]\n",
      "1777 [D loss: -27459.287109] [G loss: -6455.861328]\n",
      "1778 [D loss: -27642.302734] [G loss: -6883.816406]\n",
      "1779 [D loss: -27508.677734] [G loss: -7147.518555]\n",
      "1780 [D loss: -27613.892578] [G loss: -6907.824219]\n",
      "1781 [D loss: -27731.457031] [G loss: -6734.369141]\n",
      "1782 [D loss: -27730.433594] [G loss: -6499.178711]\n",
      "1783 [D loss: -27697.376953] [G loss: -6907.527344]\n",
      "1784 [D loss: -27658.644531] [G loss: -6673.881836]\n",
      "1785 [D loss: -27795.152344] [G loss: -7259.031250]\n",
      "1786 [D loss: -27844.447266] [G loss: -6789.441406]\n",
      "1787 [D loss: -27701.294922] [G loss: -6257.424316]\n",
      "1788 [D loss: -27859.281250] [G loss: -6770.018555]\n",
      "1789 [D loss: -27663.363281] [G loss: -6272.879883]\n",
      "1790 [D loss: -27844.621094] [G loss: -6555.903320]\n",
      "1791 [D loss: -27769.453125] [G loss: -7163.687500]\n",
      "1792 [D loss: -27947.183594] [G loss: -6659.497559]\n",
      "1793 [D loss: -27973.474609] [G loss: -6423.904785]\n",
      "1794 [D loss: -28055.900391] [G loss: -6611.217773]\n",
      "1795 [D loss: -28027.060547] [G loss: -6792.945312]\n",
      "1796 [D loss: -28074.449219] [G loss: -6856.715332]\n",
      "1797 [D loss: -28060.689453] [G loss: -6695.387695]\n",
      "1798 [D loss: -28121.933594] [G loss: -6591.121094]\n",
      "1799 [D loss: -28137.527344] [G loss: -6771.907227]\n",
      "1800 [D loss: -27951.066406] [G loss: -6410.960938]\n",
      "1801 [D loss: -28180.794922] [G loss: -6055.552734]\n",
      "1802 [D loss: -28232.394531] [G loss: -6944.182129]\n",
      "1803 [D loss: -28314.783203] [G loss: -6636.676270]\n",
      "1804 [D loss: -28305.933594] [G loss: -6502.056152]\n",
      "1805 [D loss: -28183.228516] [G loss: -6640.508301]\n",
      "1806 [D loss: -28315.287109] [G loss: -6982.324219]\n",
      "1807 [D loss: -28318.644531] [G loss: -6601.852051]\n",
      "1808 [D loss: -28364.412109] [G loss: -6775.307617]\n",
      "1809 [D loss: -28342.900391] [G loss: -7150.566406]\n",
      "1810 [D loss: -28333.314453] [G loss: -6917.319824]\n",
      "1811 [D loss: -28366.898438] [G loss: -6995.927734]\n",
      "1812 [D loss: -28446.689453] [G loss: -7222.465820]\n",
      "1813 [D loss: -28522.119141] [G loss: -6445.109375]\n",
      "1814 [D loss: -28423.460938] [G loss: -7028.867676]\n",
      "1815 [D loss: -28526.580078] [G loss: -6899.591797]\n",
      "1816 [D loss: -28558.183594] [G loss: -6499.764648]\n",
      "1817 [D loss: -28489.503906] [G loss: -7061.713867]\n",
      "1818 [D loss: -28573.816406] [G loss: -7208.644043]\n",
      "1819 [D loss: -28556.128906] [G loss: -6765.110352]\n",
      "1820 [D loss: -28624.617188] [G loss: -6996.579590]\n",
      "1821 [D loss: -28568.556641] [G loss: -7070.416992]\n",
      "1822 [D loss: -28597.486328] [G loss: -6482.344727]\n",
      "1823 [D loss: -28599.640625] [G loss: -6624.787109]\n",
      "1824 [D loss: -28710.667969] [G loss: -6730.740234]\n",
      "1825 [D loss: -28771.507812] [G loss: -6545.983398]\n",
      "1826 [D loss: -28720.486328] [G loss: -6860.921387]\n",
      "1827 [D loss: -28883.908203] [G loss: -7203.932617]\n",
      "1828 [D loss: -28770.650391] [G loss: -6620.966797]\n",
      "1829 [D loss: -28877.560547] [G loss: -6527.279785]\n",
      "1830 [D loss: -28778.892578] [G loss: -7244.607422]\n",
      "1831 [D loss: -28934.388672] [G loss: -6760.184570]\n",
      "1832 [D loss: -28928.365234] [G loss: -6930.525391]\n",
      "1833 [D loss: -28873.269531] [G loss: -6776.733398]\n",
      "1834 [D loss: -29094.369141] [G loss: -6873.865234]\n",
      "1835 [D loss: -29064.945312] [G loss: -7571.065918]\n",
      "1836 [D loss: -29023.570312] [G loss: -7098.867188]\n",
      "1837 [D loss: -29043.650391] [G loss: -7030.496094]\n",
      "1838 [D loss: -29112.876953] [G loss: -6674.849121]\n",
      "1839 [D loss: -29122.093750] [G loss: -7319.906738]\n",
      "1840 [D loss: -28972.539062] [G loss: -6818.174805]\n",
      "1841 [D loss: -29179.384766] [G loss: -6909.226562]\n",
      "1842 [D loss: -29052.847656] [G loss: -6844.715820]\n",
      "1843 [D loss: -29243.406250] [G loss: -7319.776367]\n",
      "1844 [D loss: -29224.693359] [G loss: -6555.760742]\n",
      "1845 [D loss: -29258.958984] [G loss: -6893.440430]\n",
      "1846 [D loss: -29260.439453] [G loss: -6813.145508]\n",
      "1847 [D loss: -29334.888672] [G loss: -6988.687988]\n",
      "1848 [D loss: -29251.035156] [G loss: -6810.531250]\n",
      "1849 [D loss: -29335.925781] [G loss: -7023.502930]\n",
      "1850 [D loss: -29283.470703] [G loss: -6663.998047]\n",
      "1851 [D loss: -29367.025391] [G loss: -7072.939453]\n",
      "1852 [D loss: -29419.480469] [G loss: -7060.767578]\n",
      "1853 [D loss: -29483.767578] [G loss: -7383.483398]\n",
      "1854 [D loss: -29393.359375] [G loss: -7191.192383]\n",
      "1855 [D loss: -29262.859375] [G loss: -7168.801270]\n",
      "1856 [D loss: -29573.373047] [G loss: -7217.958008]\n",
      "1857 [D loss: -29641.722656] [G loss: -7025.466797]\n",
      "1858 [D loss: -29545.906250] [G loss: -7400.593750]\n",
      "1859 [D loss: -29604.722656] [G loss: -6539.197266]\n",
      "1860 [D loss: -29706.423828] [G loss: -6954.508789]\n",
      "1861 [D loss: -29584.091797] [G loss: -7281.133301]\n",
      "1862 [D loss: -29575.716797] [G loss: -7014.642578]\n",
      "1863 [D loss: -29680.091797] [G loss: -7295.190430]\n",
      "1864 [D loss: -29709.591797] [G loss: -7290.250488]\n",
      "1865 [D loss: -29677.478516] [G loss: -7335.806641]\n",
      "1866 [D loss: -29398.917969] [G loss: -7108.219727]\n",
      "1867 [D loss: -29793.681641] [G loss: -6922.330566]\n",
      "1868 [D loss: -29771.017578] [G loss: -6961.896484]\n",
      "1869 [D loss: -29820.582031] [G loss: -7062.479492]\n",
      "1870 [D loss: -29913.814453] [G loss: -7034.274414]\n",
      "1871 [D loss: -29878.011719] [G loss: -7254.980469]\n",
      "1872 [D loss: -29884.384766] [G loss: -7092.415039]\n",
      "1873 [D loss: -29881.027344] [G loss: -7038.224609]\n",
      "1874 [D loss: -29929.703125] [G loss: -7020.426758]\n",
      "1875 [D loss: -29954.763672] [G loss: -7153.063965]\n",
      "1876 [D loss: -30017.433594] [G loss: -7522.510254]\n",
      "1877 [D loss: -30100.289062] [G loss: -6687.047852]\n",
      "1878 [D loss: -30104.292969] [G loss: -7536.425293]\n",
      "1879 [D loss: -30067.539062] [G loss: -7480.000488]\n",
      "1880 [D loss: -30153.957031] [G loss: -7245.425293]\n",
      "1881 [D loss: -30016.531250] [G loss: -7429.216797]\n",
      "1882 [D loss: -30111.482422] [G loss: -7130.644043]\n",
      "1883 [D loss: -30182.560547] [G loss: -6833.133789]\n",
      "1884 [D loss: -30262.496094] [G loss: -7534.450195]\n",
      "1885 [D loss: -30255.130859] [G loss: -7535.752930]\n",
      "1886 [D loss: -30339.425781] [G loss: -7646.333984]\n",
      "1887 [D loss: -30257.207031] [G loss: -7142.607422]\n",
      "1888 [D loss: -30319.884766] [G loss: -7556.535645]\n",
      "1889 [D loss: -30374.312500] [G loss: -7022.694336]\n",
      "1890 [D loss: -30389.199219] [G loss: -7409.758789]\n",
      "1891 [D loss: -30275.626953] [G loss: -7280.205566]\n",
      "1892 [D loss: -30408.486328] [G loss: -7130.137207]\n",
      "1893 [D loss: -30456.554688] [G loss: -7486.642578]\n",
      "1894 [D loss: -30513.275391] [G loss: -6810.915039]\n",
      "1895 [D loss: -30509.179688] [G loss: -7307.860840]\n",
      "1896 [D loss: -30516.107422] [G loss: -7483.668457]\n",
      "1897 [D loss: -30607.740234] [G loss: -7632.121094]\n",
      "1898 [D loss: -30463.498047] [G loss: -7654.491211]\n",
      "1899 [D loss: -30651.951172] [G loss: -7406.431641]\n",
      "1900 [D loss: -30660.351562] [G loss: -7239.849609]\n",
      "1901 [D loss: -30584.074219] [G loss: -7918.424805]\n",
      "1902 [D loss: -30732.990234] [G loss: -7961.223633]\n",
      "1903 [D loss: -30804.578125] [G loss: -7289.602539]\n",
      "1904 [D loss: -30813.636719] [G loss: -6969.948242]\n",
      "1905 [D loss: -30695.214844] [G loss: -7023.538086]\n",
      "1906 [D loss: -30790.500000] [G loss: -7312.237305]\n",
      "1907 [D loss: -30816.882812] [G loss: -7322.154297]\n",
      "1908 [D loss: -30942.455078] [G loss: -7575.806152]\n",
      "1909 [D loss: -30862.064453] [G loss: -7685.610352]\n",
      "1910 [D loss: -30735.214844] [G loss: -7983.695312]\n",
      "1911 [D loss: -30810.724609] [G loss: -7438.854980]\n",
      "1912 [D loss: -31019.367188] [G loss: -7177.870117]\n",
      "1913 [D loss: -31001.037109] [G loss: -7817.092285]\n",
      "1914 [D loss: -31030.574219] [G loss: -7779.550781]\n",
      "1915 [D loss: -31009.640625] [G loss: -7487.290527]\n",
      "1916 [D loss: -31096.751953] [G loss: -7691.882812]\n",
      "1917 [D loss: -31084.714844] [G loss: -7731.825684]\n",
      "1918 [D loss: -31062.759766] [G loss: -7524.542969]\n",
      "1919 [D loss: -31072.666016] [G loss: -7145.002930]\n",
      "1920 [D loss: -31087.373047] [G loss: -7424.944336]\n",
      "1921 [D loss: -31164.814453] [G loss: -7036.037598]\n",
      "1922 [D loss: -31260.800781] [G loss: -7266.413574]\n",
      "1923 [D loss: -31263.949219] [G loss: -7336.934082]\n",
      "1924 [D loss: -31242.726562] [G loss: -7558.528320]\n",
      "1925 [D loss: -31303.488281] [G loss: -7110.586914]\n",
      "1926 [D loss: -31365.740234] [G loss: -7167.706055]\n",
      "1927 [D loss: -31338.001953] [G loss: -7447.393555]\n",
      "1928 [D loss: -31358.498047] [G loss: -6589.041992]\n",
      "1929 [D loss: -31401.648438] [G loss: -7761.490234]\n",
      "1930 [D loss: -31414.394531] [G loss: -8294.868164]\n",
      "1931 [D loss: -31556.814453] [G loss: -7425.934570]\n",
      "1932 [D loss: -31453.779297] [G loss: -7547.998047]\n",
      "1933 [D loss: -31485.306641] [G loss: -7892.341797]\n",
      "1934 [D loss: -31608.009766] [G loss: -7338.016602]\n",
      "1935 [D loss: -31573.625000] [G loss: -7267.692871]\n",
      "1936 [D loss: -31397.636719] [G loss: -7290.148438]\n",
      "1937 [D loss: -31625.425781] [G loss: -7425.135742]\n",
      "1938 [D loss: -31742.615234] [G loss: -7369.435547]\n",
      "1939 [D loss: -31621.214844] [G loss: -7280.978027]\n",
      "1940 [D loss: -31744.492188] [G loss: -7613.033691]\n",
      "1941 [D loss: -31612.439453] [G loss: -7349.415039]\n",
      "1942 [D loss: -31506.677734] [G loss: -7445.712891]\n",
      "1943 [D loss: -31787.945312] [G loss: -7752.619141]\n",
      "1944 [D loss: -31794.167969] [G loss: -7798.227051]\n",
      "1945 [D loss: -31696.365234] [G loss: -7491.278320]\n",
      "1946 [D loss: -31908.703125] [G loss: -7442.169434]\n",
      "1947 [D loss: -31911.654297] [G loss: -7908.875977]\n",
      "1948 [D loss: -31944.599609] [G loss: -8162.498535]\n",
      "1949 [D loss: -31907.791016] [G loss: -8043.978516]\n",
      "1950 [D loss: -31841.578125] [G loss: -7200.288086]\n",
      "1951 [D loss: -31890.542969] [G loss: -7946.261230]\n",
      "1952 [D loss: -32006.041016] [G loss: -7780.096680]\n",
      "1953 [D loss: -32103.425781] [G loss: -7559.371582]\n",
      "1954 [D loss: -31946.035156] [G loss: -7855.668457]\n",
      "1955 [D loss: -32094.039062] [G loss: -7894.817383]\n",
      "1956 [D loss: -32034.494141] [G loss: -7717.468750]\n",
      "1957 [D loss: -32001.201172] [G loss: -7146.065430]\n",
      "1958 [D loss: -32103.009766] [G loss: -7863.571289]\n",
      "1959 [D loss: -32247.261719] [G loss: -7600.263672]\n",
      "1960 [D loss: -32133.625000] [G loss: -7703.216797]\n",
      "1961 [D loss: -32255.998047] [G loss: -8187.041016]\n",
      "1962 [D loss: -32368.970703] [G loss: -7897.413086]\n",
      "1963 [D loss: -32213.601562] [G loss: -7383.035156]\n",
      "1964 [D loss: -32372.068359] [G loss: -7520.944336]\n",
      "1965 [D loss: -32259.042969] [G loss: -8118.434570]\n",
      "1966 [D loss: -32228.908203] [G loss: -7662.123047]\n",
      "1967 [D loss: -32280.478516] [G loss: -7763.983398]\n",
      "1968 [D loss: -32265.757812] [G loss: -8058.361328]\n",
      "1969 [D loss: -32371.529297] [G loss: -7779.429688]\n",
      "1970 [D loss: -32381.939453] [G loss: -7558.659180]\n",
      "1971 [D loss: -32560.980469] [G loss: -7720.122070]\n",
      "1972 [D loss: -32418.935547] [G loss: -7626.903320]\n",
      "1973 [D loss: -32578.058594] [G loss: -8522.687500]\n",
      "1974 [D loss: -32618.328125] [G loss: -7614.855957]\n",
      "1975 [D loss: -32512.916016] [G loss: -7768.469727]\n",
      "1976 [D loss: -32552.986328] [G loss: -7767.309570]\n",
      "1977 [D loss: -32701.572266] [G loss: -7550.416992]\n",
      "1978 [D loss: -32686.970703] [G loss: -7938.828125]\n",
      "1979 [D loss: -32595.791016] [G loss: -7988.548828]\n",
      "1980 [D loss: -32671.187500] [G loss: -7980.850586]\n",
      "1981 [D loss: -32718.382812] [G loss: -7876.944336]\n",
      "1982 [D loss: -32674.117188] [G loss: -7603.410156]\n",
      "1983 [D loss: -32775.007812] [G loss: -7939.708984]\n",
      "1984 [D loss: -32788.496094] [G loss: -8269.266602]\n",
      "1985 [D loss: -32756.292969] [G loss: -7884.071777]\n",
      "1986 [D loss: -32901.492188] [G loss: -8167.118652]\n",
      "1987 [D loss: -32823.179688] [G loss: -8220.436523]\n",
      "1988 [D loss: -32891.085938] [G loss: -7624.777832]\n",
      "1989 [D loss: -32902.316406] [G loss: -8182.494141]\n",
      "1990 [D loss: -33024.777344] [G loss: -7783.058594]\n",
      "1991 [D loss: -33020.332031] [G loss: -7988.477051]\n",
      "1992 [D loss: -33070.906250] [G loss: -8111.875000]\n",
      "1993 [D loss: -32989.894531] [G loss: -8293.013672]\n",
      "1994 [D loss: -33141.410156] [G loss: -8547.367188]\n",
      "1995 [D loss: -33042.898438] [G loss: -8135.932129]\n",
      "1996 [D loss: -33121.039062] [G loss: -7910.444336]\n",
      "1997 [D loss: -33131.183594] [G loss: -7415.030273]\n",
      "1998 [D loss: -33200.726562] [G loss: -8448.276367]\n",
      "1999 [D loss: -33231.804688] [G loss: -7499.766602]\n",
      "2000 [D loss: -33081.035156] [G loss: -7529.995117]\n",
      "2001 [D loss: -33315.339844] [G loss: -8421.897461]\n",
      "2002 [D loss: -33246.300781] [G loss: -8390.085938]\n",
      "2003 [D loss: -33381.925781] [G loss: -8175.348145]\n",
      "2004 [D loss: -33295.941406] [G loss: -8105.977051]\n",
      "2005 [D loss: -33372.550781] [G loss: -7901.770508]\n",
      "2006 [D loss: -33325.628906] [G loss: -8297.919922]\n",
      "2007 [D loss: -33433.621094] [G loss: -7766.166016]\n",
      "2008 [D loss: -33371.242188] [G loss: -7731.643555]\n",
      "2009 [D loss: -33542.007812] [G loss: -8922.396484]\n",
      "2010 [D loss: -33385.003906] [G loss: -8335.832031]\n",
      "2011 [D loss: -33610.675781] [G loss: -9019.208984]\n",
      "2012 [D loss: -33549.109375] [G loss: -8117.272461]\n",
      "2013 [D loss: -33679.382812] [G loss: -7936.199219]\n",
      "2014 [D loss: -33582.585938] [G loss: -8070.416016]\n",
      "2015 [D loss: -33494.960938] [G loss: -8060.708984]\n",
      "2016 [D loss: -33700.898438] [G loss: -8457.183594]\n",
      "2017 [D loss: -33484.500000] [G loss: -8144.292480]\n",
      "2018 [D loss: -33515.726562] [G loss: -8181.560547]\n",
      "2019 [D loss: -33692.140625] [G loss: -7883.284180]\n",
      "2020 [D loss: -33702.816406] [G loss: -8301.968750]\n",
      "2021 [D loss: -33834.039062] [G loss: -8112.344238]\n",
      "2022 [D loss: -33769.671875] [G loss: -8537.966797]\n",
      "2023 [D loss: -33802.101562] [G loss: -8368.366211]\n",
      "2024 [D loss: -33864.289062] [G loss: -8065.934570]\n",
      "2025 [D loss: -33885.777344] [G loss: -8486.298828]\n",
      "2026 [D loss: -33836.417969] [G loss: -8155.342773]\n",
      "2027 [D loss: -34040.441406] [G loss: -9003.583008]\n",
      "2028 [D loss: -34049.246094] [G loss: -8586.543945]\n",
      "2029 [D loss: -34040.132812] [G loss: -8668.248047]\n",
      "2030 [D loss: -33944.667969] [G loss: -8287.394531]\n",
      "2031 [D loss: -34179.316406] [G loss: -8849.562500]\n",
      "2032 [D loss: -33974.605469] [G loss: -8392.059570]\n",
      "2033 [D loss: -34063.570312] [G loss: -8060.976074]\n",
      "2034 [D loss: -34121.753906] [G loss: -8215.204102]\n",
      "2035 [D loss: -34086.238281] [G loss: -8636.458984]\n",
      "2036 [D loss: -34150.050781] [G loss: -8648.964844]\n",
      "2037 [D loss: -34213.730469] [G loss: -7841.732422]\n",
      "2038 [D loss: -34255.953125] [G loss: -8081.020996]\n",
      "2039 [D loss: -34030.453125] [G loss: -8432.941406]\n",
      "2040 [D loss: -34260.546875] [G loss: -8333.353516]\n",
      "2041 [D loss: -34172.968750] [G loss: -8276.103516]\n",
      "2042 [D loss: -34306.011719] [G loss: -8458.244141]\n",
      "2043 [D loss: -34300.933594] [G loss: -8944.384766]\n",
      "2044 [D loss: -34437.878906] [G loss: -9001.599609]\n",
      "2045 [D loss: -34512.992188] [G loss: -8819.867188]\n",
      "2046 [D loss: -34355.207031] [G loss: -8812.310547]\n",
      "2047 [D loss: -34376.601562] [G loss: -8022.479492]\n",
      "2048 [D loss: -34596.890625] [G loss: -8241.316406]\n",
      "2049 [D loss: -34490.890625] [G loss: -8181.863770]\n",
      "2050 [D loss: -34662.988281] [G loss: -8590.101562]\n",
      "2051 [D loss: -34480.234375] [G loss: -8460.642578]\n",
      "2052 [D loss: -34591.031250] [G loss: -8081.960938]\n",
      "2053 [D loss: -34687.894531] [G loss: -8487.316406]\n",
      "2054 [D loss: -34710.578125] [G loss: -8874.236328]\n",
      "2055 [D loss: -34645.429688] [G loss: -9134.839844]\n",
      "2056 [D loss: -34787.449219] [G loss: -8513.988281]\n",
      "2057 [D loss: -34649.011719] [G loss: -8595.559570]\n",
      "2058 [D loss: -34685.757812] [G loss: -8826.686523]\n",
      "2059 [D loss: -34853.035156] [G loss: -8467.689453]\n",
      "2060 [D loss: -34784.085938] [G loss: -8358.212891]\n",
      "2061 [D loss: -34809.113281] [G loss: -8423.716797]\n",
      "2062 [D loss: -34894.972656] [G loss: -8575.599609]\n",
      "2063 [D loss: -34882.750000] [G loss: -8856.141602]\n",
      "2064 [D loss: -34952.757812] [G loss: -7707.387207]\n",
      "2065 [D loss: -34837.214844] [G loss: -8400.054688]\n",
      "2066 [D loss: -34934.054688] [G loss: -8592.576172]\n",
      "2067 [D loss: -35203.816406] [G loss: -8794.357422]\n",
      "2068 [D loss: -35135.027344] [G loss: -8525.753906]\n",
      "2069 [D loss: -34914.722656] [G loss: -8082.808105]\n",
      "2070 [D loss: -35035.429688] [G loss: -8761.259766]\n",
      "2071 [D loss: -35111.917969] [G loss: -8726.339844]\n",
      "2072 [D loss: -35096.421875] [G loss: -8134.368164]\n",
      "2073 [D loss: -35127.925781] [G loss: -8929.623047]\n",
      "2074 [D loss: -35123.929688] [G loss: -9286.158203]\n",
      "2075 [D loss: -35154.433594] [G loss: -8925.541992]\n",
      "2076 [D loss: -35288.152344] [G loss: -8960.177734]\n",
      "2077 [D loss: -35252.003906] [G loss: -8638.078125]\n",
      "2078 [D loss: -35388.972656] [G loss: -8316.095703]\n",
      "2079 [D loss: -35377.859375] [G loss: -8379.054688]\n",
      "2080 [D loss: -35173.250000] [G loss: -8597.309570]\n",
      "2081 [D loss: -35357.187500] [G loss: -8949.146484]\n",
      "2082 [D loss: -35461.539062] [G loss: -8879.173828]\n",
      "2083 [D loss: -35393.953125] [G loss: -8289.330078]\n",
      "2084 [D loss: -35414.484375] [G loss: -8497.984375]\n",
      "2085 [D loss: -35419.921875] [G loss: -8653.443359]\n",
      "2086 [D loss: -35492.460938] [G loss: -9103.677734]\n",
      "2087 [D loss: -35579.410156] [G loss: -8968.189453]\n",
      "2088 [D loss: -35416.937500] [G loss: -8593.820312]\n",
      "2089 [D loss: -35638.316406] [G loss: -8250.857422]\n",
      "2090 [D loss: -35645.835938] [G loss: -8693.902344]\n",
      "2091 [D loss: -35679.066406] [G loss: -8997.994141]\n",
      "2092 [D loss: -35595.742188] [G loss: -8925.673828]\n",
      "2093 [D loss: -35719.757812] [G loss: -8912.251953]\n",
      "2094 [D loss: -35602.003906] [G loss: -9097.009766]\n",
      "2095 [D loss: -35677.222656] [G loss: -9023.037109]\n",
      "2096 [D loss: -35692.324219] [G loss: -8419.068359]\n",
      "2097 [D loss: -35595.839844] [G loss: -9068.980469]\n",
      "2098 [D loss: -35774.113281] [G loss: -9266.941406]\n",
      "2099 [D loss: -35821.308594] [G loss: -8614.104492]\n",
      "2100 [D loss: -35833.609375] [G loss: -8610.297852]\n",
      "2101 [D loss: -35938.144531] [G loss: -8682.210938]\n",
      "2102 [D loss: -35896.925781] [G loss: -9084.036133]\n",
      "2103 [D loss: -35898.656250] [G loss: -8623.988281]\n",
      "2104 [D loss: -35969.078125] [G loss: -8780.245117]\n",
      "2105 [D loss: -36156.183594] [G loss: -9325.875000]\n",
      "2106 [D loss: -35927.613281] [G loss: -8880.059570]\n",
      "2107 [D loss: -36074.886719] [G loss: -8336.681641]\n",
      "2108 [D loss: -36258.425781] [G loss: -8345.828125]\n",
      "2109 [D loss: -36069.882812] [G loss: -8380.883789]\n",
      "2110 [D loss: -35965.945312] [G loss: -8968.232422]\n",
      "2111 [D loss: -36193.171875] [G loss: -9065.378906]\n",
      "2112 [D loss: -36108.679688] [G loss: -8915.460938]\n",
      "2113 [D loss: -36147.902344] [G loss: -9123.123047]\n",
      "2114 [D loss: -36255.320312] [G loss: -8930.086914]\n",
      "2115 [D loss: -36204.964844] [G loss: -8958.624023]\n",
      "2116 [D loss: -36114.218750] [G loss: -8845.607422]\n",
      "2117 [D loss: -36297.812500] [G loss: -9074.284180]\n",
      "2118 [D loss: -36346.636719] [G loss: -8845.108398]\n",
      "2119 [D loss: -36356.300781] [G loss: -9006.077148]\n",
      "2120 [D loss: -36198.656250] [G loss: -9229.684570]\n",
      "2121 [D loss: -36483.402344] [G loss: -8606.482422]\n",
      "2122 [D loss: -36407.117188] [G loss: -9591.503906]\n",
      "2123 [D loss: -36560.847656] [G loss: -9152.832031]\n",
      "2124 [D loss: -36555.984375] [G loss: -9437.241211]\n",
      "2125 [D loss: -36590.042969] [G loss: -9125.265625]\n",
      "2126 [D loss: -36622.742188] [G loss: -9067.682617]\n",
      "2127 [D loss: -36545.902344] [G loss: -9268.375000]\n",
      "2128 [D loss: -36668.257812] [G loss: -8899.328125]\n",
      "2129 [D loss: -36728.792969] [G loss: -8964.566406]\n",
      "2130 [D loss: -36634.648438] [G loss: -8509.099609]\n",
      "2131 [D loss: -36623.964844] [G loss: -8574.009766]\n",
      "2132 [D loss: -36800.214844] [G loss: -9021.214844]\n",
      "2133 [D loss: -36780.132812] [G loss: -8687.116211]\n",
      "2134 [D loss: -36806.394531] [G loss: -8504.009766]\n",
      "2135 [D loss: -36889.296875] [G loss: -8763.679688]\n",
      "2136 [D loss: -36730.050781] [G loss: -9238.947266]\n",
      "2137 [D loss: -36758.628906] [G loss: -8636.904297]\n",
      "2138 [D loss: -36955.550781] [G loss: -8311.943359]\n",
      "2139 [D loss: -36922.636719] [G loss: -8636.041016]\n",
      "2140 [D loss: -36982.179688] [G loss: -9019.099609]\n",
      "2141 [D loss: -36934.246094] [G loss: -9382.636719]\n",
      "2142 [D loss: -36999.328125] [G loss: -9435.712891]\n",
      "2143 [D loss: -36888.917969] [G loss: -9108.005859]\n",
      "2144 [D loss: -36971.449219] [G loss: -9231.062500]\n",
      "2145 [D loss: -36921.468750] [G loss: -9275.425781]\n",
      "2146 [D loss: -37132.968750] [G loss: -9061.730469]\n",
      "2147 [D loss: -37087.289062] [G loss: -9318.066406]\n",
      "2148 [D loss: -37136.000000] [G loss: -9239.676758]\n",
      "2149 [D loss: -37176.351562] [G loss: -8785.273438]\n",
      "2150 [D loss: -37081.746094] [G loss: -9507.618164]\n",
      "2151 [D loss: -37149.664062] [G loss: -9584.650391]\n",
      "2152 [D loss: -37248.332031] [G loss: -8538.140625]\n",
      "2153 [D loss: -37280.480469] [G loss: -9487.999023]\n",
      "2154 [D loss: -37302.785156] [G loss: -9887.507812]\n",
      "2155 [D loss: -37488.593750] [G loss: -9200.214844]\n",
      "2156 [D loss: -37345.601562] [G loss: -9261.708984]\n",
      "2157 [D loss: -37244.355469] [G loss: -9150.880859]\n",
      "2158 [D loss: -37470.187500] [G loss: -9515.676758]\n",
      "2159 [D loss: -37466.253906] [G loss: -8700.325195]\n",
      "2160 [D loss: -37399.675781] [G loss: -9227.032227]\n",
      "2161 [D loss: -37422.652344] [G loss: -9531.859375]\n",
      "2162 [D loss: -37521.105469] [G loss: -9526.574219]\n",
      "2163 [D loss: -37549.843750] [G loss: -9201.894531]\n",
      "2164 [D loss: -37686.843750] [G loss: -9578.104492]\n",
      "2165 [D loss: -37595.671875] [G loss: -8669.564453]\n",
      "2166 [D loss: -37660.355469] [G loss: -9390.691406]\n",
      "2167 [D loss: -37648.531250] [G loss: -9719.700195]\n",
      "2168 [D loss: -37661.789062] [G loss: -9180.692383]\n",
      "2169 [D loss: -37660.070312] [G loss: -9276.560547]\n",
      "2170 [D loss: -37758.980469] [G loss: -9410.148438]\n",
      "2171 [D loss: -37690.488281] [G loss: -9267.782227]\n",
      "2172 [D loss: -37634.722656] [G loss: -9733.070312]\n",
      "2173 [D loss: -37567.773438] [G loss: -9615.637695]\n",
      "2174 [D loss: -37822.281250] [G loss: -10043.373047]\n",
      "2175 [D loss: -37852.601562] [G loss: -9424.041992]\n",
      "2176 [D loss: -38040.050781] [G loss: -10127.121094]\n",
      "2177 [D loss: -37994.875000] [G loss: -9150.526367]\n",
      "2178 [D loss: -37998.964844] [G loss: -9587.134766]\n",
      "2179 [D loss: -37997.265625] [G loss: -9560.357422]\n",
      "2180 [D loss: -37997.304688] [G loss: -9234.432617]\n",
      "2181 [D loss: -38062.484375] [G loss: -9404.150391]\n",
      "2182 [D loss: -38078.710938] [G loss: -9779.658203]\n",
      "2183 [D loss: -37975.335938] [G loss: -9585.148438]\n",
      "2184 [D loss: -38178.710938] [G loss: -9371.501953]\n",
      "2185 [D loss: -37973.296875] [G loss: -9513.587891]\n",
      "2186 [D loss: -38224.625000] [G loss: -9014.001953]\n",
      "2187 [D loss: -38215.281250] [G loss: -9347.441406]\n",
      "2188 [D loss: -38229.976562] [G loss: -9185.601562]\n",
      "2189 [D loss: -38359.050781] [G loss: -9472.439453]\n",
      "2190 [D loss: -38391.894531] [G loss: -9378.323242]\n",
      "2191 [D loss: -38468.664062] [G loss: -9707.526367]\n",
      "2192 [D loss: -38417.132812] [G loss: -9678.598633]\n",
      "2193 [D loss: -38210.085938] [G loss: -9408.439453]\n",
      "2194 [D loss: -38417.039062] [G loss: -9084.595703]\n",
      "2195 [D loss: -38444.843750] [G loss: -9418.123047]\n",
      "2196 [D loss: -38441.238281] [G loss: -9473.046875]\n",
      "2197 [D loss: -38483.308594] [G loss: -9991.572266]\n",
      "2198 [D loss: -38565.140625] [G loss: -9477.187500]\n",
      "2199 [D loss: -38624.304688] [G loss: -10346.179688]\n",
      "2200 [D loss: -38553.410156] [G loss: -9458.449219]\n",
      "2201 [D loss: -38505.332031] [G loss: -9971.550781]\n",
      "2202 [D loss: -38604.929688] [G loss: -9382.234375]\n",
      "2203 [D loss: -38535.972656] [G loss: -9675.242188]\n",
      "2204 [D loss: -38561.769531] [G loss: -9601.021484]\n",
      "2205 [D loss: -38707.824219] [G loss: -10308.867188]\n",
      "2206 [D loss: -38639.273438] [G loss: -9282.898438]\n",
      "2207 [D loss: -38886.195312] [G loss: -10589.298828]\n",
      "2208 [D loss: -38855.269531] [G loss: -10067.197266]\n",
      "2209 [D loss: -38682.949219] [G loss: -9913.494141]\n",
      "2210 [D loss: -38927.191406] [G loss: -10017.708984]\n",
      "2211 [D loss: -38909.277344] [G loss: -10129.156250]\n",
      "2212 [D loss: -38848.550781] [G loss: -9981.661133]\n",
      "2213 [D loss: -38949.898438] [G loss: -9109.728516]\n",
      "2214 [D loss: -39046.531250] [G loss: -10043.677734]\n",
      "2215 [D loss: -38866.300781] [G loss: -9190.664062]\n",
      "2216 [D loss: -39163.667969] [G loss: -10236.988281]\n",
      "2217 [D loss: -38970.832031] [G loss: -10090.835938]\n",
      "2218 [D loss: -39044.542969] [G loss: -10161.083984]\n",
      "2219 [D loss: -38977.550781] [G loss: -9805.128906]\n",
      "2220 [D loss: -39085.769531] [G loss: -9438.178711]\n",
      "2221 [D loss: -39212.132812] [G loss: -9560.539062]\n",
      "2222 [D loss: -39094.476562] [G loss: -10026.048828]\n",
      "2223 [D loss: -39193.972656] [G loss: -10008.541016]\n",
      "2224 [D loss: -39276.890625] [G loss: -10364.824219]\n",
      "2225 [D loss: -39243.800781] [G loss: -10185.759766]\n",
      "2226 [D loss: -39283.371094] [G loss: -9879.256836]\n",
      "2227 [D loss: -39337.703125] [G loss: -9462.113281]\n",
      "2228 [D loss: -39346.246094] [G loss: -10423.712891]\n",
      "2229 [D loss: -39307.246094] [G loss: -9662.681641]\n",
      "2230 [D loss: -39279.363281] [G loss: -10427.291992]\n",
      "2231 [D loss: -39318.730469] [G loss: -10043.638672]\n",
      "2232 [D loss: -39436.789062] [G loss: -9870.007812]\n",
      "2233 [D loss: -39365.277344] [G loss: -10106.833008]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24868/3010691483.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWGANGP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24868/1541094116.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[0;32m    216\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[1;31m# Train the discriminator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                 d_loss = self.discriminator_model.train_on_batch([imgs, noise],\n\u001b[0m\u001b[0;32m    219\u001b[0m                                                                 [valid, fake, dummy])\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1074\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4184\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4186\u001b[1;33m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[0;32m   4187\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[0;32m   4188\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1481\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1483\u001b[1;33m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[0;32m   1484\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1485\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wgan = WGANGP()\n",
    "wgan.train(epochs=10000, batch_size=BATCH_SIZE, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1696fff12340fbeacd8891884860ba5d4999e3a236c837e4d2afed27776e33eb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
